{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"ArcaNN ArcaNN proposes an automated enhanced sampling generation of training sets for chemically reactive machine learning interatomic potentials. In its current version, it aims to simplify and automate the iterative training process of a DeePMD-kit neural network potential for a user-chosen system. The core concepts of this training procedure could be extended to other network architectures. Key Advantages Modularity : The code is designed with modularity in mind, allowing users to finely tune the training process to fit their specific system and workflow. Traceability : Every parameter set during the procedure is recorded, ensuring great traceability. Iterative Training Process During the iterative training process, you will: Train neural network potentials. Use them as reactive force fields in molecular dynamics simulations to explore the phase space. Select and label configurations based on a query by committee approach. Train a new generation of neural network potentials again with the improved training set. This workflow, often referred to as active or concurrent learning, is inspired by DP-GEN . We adopt their naming scheme for the steps in the iterative procedure. Each iteration, or cycle, consists of the following steps: Training Exploration Labeling (Optional) Testing Ensure you understand the meaning of each step before using the code. GitHub Repository Structure You will find in our GitHub repository everything you need to set up the ArcaNN software, as well as example files that you can use as an example. The repository contains several folders: The tools/ folder contains helper scripts and files. The arcann_training/ folder contains the ArcaNN Training code. We strongly advise against modifying its contents . See ArcaNN Installation Guide for the installation. The examples/ folder contains template files to set up the iterative training procedure for your system. Within this folder you can find : The inputs/ folder with five JSON files, one per step . These files contain all the keywords used to control each step of an iteration (namely initialization , exploration , labeling , training and optionally test ), including their type and the default values taken by the code if a keyword isn't provided by the user. If the default is a list containing a single value it means that this value will be repeated and used for every system (see the corresponding section fir each step ). Note : For the exploration step some keywords have two default values, the first one will be used if the exploration is conducted with classical nuclei MD ( i.e. LAMMPS) and the second one will be used with quantum nuclei MD ( i.e. i-PI). The user_files/ folder with: A machine.json template file where all the information about your cluster should be provided (see HPC Configuration ). A input folder for each step , where skeleton files are provided as templates for writing your own inputs for the respective external programs. For example, in the exploration_lammps/ , labeling_cp2k/ and training_deepmd/ , you can find the necessecary files to perform the exploration with LAMMPS, the labeling with CP2K and the training with DeePMD-kit (see Exploration , Labeling and Training for a detailed description of the tunneable keywords). A job folder for each step, where skeleton submission files are provided as template that ArcaNN use to launch the different phases in each step when they require a HPC machine. For example, in job_exploration_lammps_slurm/ , job_labeling_CP2K_slurm , job_training_deepmd_slurm and the optional step job_test_deepmd_slurm , you can find basic Slurm submission files. You must adapt these files to ensure they work on your machine (see Usage ), but be careful not to modify the replaceable keywords (every word starting with _R_ and ending with _ ) that Arcann will replace with user-defined or auto-generated values (e.g., the wall time for labeling calculations, the cluster partition to be used, etc.).","title":"Home"},{"location":"#arcann","text":"ArcaNN proposes an automated enhanced sampling generation of training sets for chemically reactive machine learning interatomic potentials. In its current version, it aims to simplify and automate the iterative training process of a DeePMD-kit neural network potential for a user-chosen system. The core concepts of this training procedure could be extended to other network architectures.","title":"ArcaNN"},{"location":"#key-advantages","text":"Modularity : The code is designed with modularity in mind, allowing users to finely tune the training process to fit their specific system and workflow. Traceability : Every parameter set during the procedure is recorded, ensuring great traceability.","title":"Key Advantages"},{"location":"#iterative-training-process","text":"During the iterative training process, you will: Train neural network potentials. Use them as reactive force fields in molecular dynamics simulations to explore the phase space. Select and label configurations based on a query by committee approach. Train a new generation of neural network potentials again with the improved training set. This workflow, often referred to as active or concurrent learning, is inspired by DP-GEN . We adopt their naming scheme for the steps in the iterative procedure. Each iteration, or cycle, consists of the following steps: Training Exploration Labeling (Optional) Testing Ensure you understand the meaning of each step before using the code.","title":"Iterative Training Process"},{"location":"#github-repository-structure","text":"You will find in our GitHub repository everything you need to set up the ArcaNN software, as well as example files that you can use as an example. The repository contains several folders: The tools/ folder contains helper scripts and files. The arcann_training/ folder contains the ArcaNN Training code. We strongly advise against modifying its contents . See ArcaNN Installation Guide for the installation. The examples/ folder contains template files to set up the iterative training procedure for your system. Within this folder you can find : The inputs/ folder with five JSON files, one per step . These files contain all the keywords used to control each step of an iteration (namely initialization , exploration , labeling , training and optionally test ), including their type and the default values taken by the code if a keyword isn't provided by the user. If the default is a list containing a single value it means that this value will be repeated and used for every system (see the corresponding section fir each step ). Note : For the exploration step some keywords have two default values, the first one will be used if the exploration is conducted with classical nuclei MD ( i.e. LAMMPS) and the second one will be used with quantum nuclei MD ( i.e. i-PI). The user_files/ folder with: A machine.json template file where all the information about your cluster should be provided (see HPC Configuration ). A input folder for each step , where skeleton files are provided as templates for writing your own inputs for the respective external programs. For example, in the exploration_lammps/ , labeling_cp2k/ and training_deepmd/ , you can find the necessecary files to perform the exploration with LAMMPS, the labeling with CP2K and the training with DeePMD-kit (see Exploration , Labeling and Training for a detailed description of the tunneable keywords). A job folder for each step, where skeleton submission files are provided as template that ArcaNN use to launch the different phases in each step when they require a HPC machine. For example, in job_exploration_lammps_slurm/ , job_labeling_CP2K_slurm , job_training_deepmd_slurm and the optional step job_test_deepmd_slurm , you can find basic Slurm submission files. You must adapt these files to ensure they work on your machine (see Usage ), but be careful not to modify the replaceable keywords (every word starting with _R_ and ending with _ ) that Arcann will replace with user-defined or auto-generated values (e.g., the wall time for labeling calculations, the cluster partition to be used, etc.).","title":"GitHub Repository Structure"},{"location":"contributions/contributions/","text":"Contributions We warmly welcome contributions to ArcaNN. If you have ideas, code contributions, or suggested optimizations, please feel free to submit them.","title":"Contributions"},{"location":"contributions/contributions/#contributions","text":"We warmly welcome contributions to ArcaNN. If you have ideas, code contributions, or suggested optimizations, please feel free to submit them.","title":"Contributions"},{"location":"contributions/unexpected_behavior/","text":"Unexpected Behavior If you encounter any bugs or issues while working with ArcaNN, we encourage you to report them. Please don't hesitate to open an issue on our GitHub repository. To assist us in identifying the problem, you can use the -v 1 argument with ArcaNN to enable more verbose logging.","title":"Unexpected Behavior"},{"location":"contributions/unexpected_behavior/#unexpected-behavior","text":"If you encounter any bugs or issues while working with ArcaNN, we encourage you to report them. Please don't hesitate to open an issue on our GitHub repository. To assist us in identifying the problem, you can use the -v 1 argument with ArcaNN to enable more verbose logging.","title":"Unexpected Behavior"},{"location":"examples/sn2/","text":"SN2 Here we introduce the basic usage of the ArcaNN software, ilustrated by a SN2 reaction. All the files are available in the GitHub Repository ; and after ArcaNN installation, you will find them at examples/sn2_ch3cl_br/ inside your local arcann_traininig directory. The iterative training and dataset generation for the SN2 reaction, comprised two iterative trainings : a first non-reactive training was performed on reactant and products structures, followed by a reactive training where transition structures were generated. The files set up for the non-reactive SN2 ArcaNN training is illustrated bellow. Then, the ArcaNN inputs for each step of the first iteration and the corresponding control json files are detailed. User files We will start by creating a user_files/ directory (See Iterative procedure prerequisites ) where we will include the necessary files for each step of the procedure. You also need to create a data/ directory where the initial labeled datasets will be stored. For the reactive training, you will store the datasets of the non-reactive training in the corresponding data/ directory, together with the initial datasets. For the non-reactive training, 6 systems were defined : 3 systems to explore the reactant basin ( ch3cl_br_close_300K , ch3cl_br_free_300K , ch3cl_br_smd_300K ) and 3 systems to explore the product basin ( ch3br_cl_close_300K , ch3br_cl_free_300K , ch3br_cl_smd_300K ). In the user_files/ folder you will find the following files for each one of the systems (for clarity purposes, we only indicate the files of the ch3cl_br_close_300K system here). Note also that hpc1 and hpc2 are the machine keywords indicated in the machine.json file, see HPC Configuration . JSON FILES machine.json : file containing the cluster parameters. dp_train_2.1.json : input for DeePMD trainings. JOB FILES job_lammps-deepmd_explore_gpu_hpc1.sh and job-array_lammps-deepmd_explore_gpu_hpc1.sh : job scripts for exploration job_CP2K_label_cpu_hpc1.sh and job-array_CP2K_label_hpc1.sh : job scripts for labeling job_deepmd_compress_gpu_hpc1.sh , job_deepmd_freeze_gpu_hpc1.sh and job_deepmd_train_gpu_hpc1.sh job scripts for training CP2K FILES 1_ch3cl_br_close_300K_labeling_XXXXX_hpc1.inp , 2_ch3cl_br_close_300K_labeling_XXXXX_hpc1.inp , 1_ch3cl_br_close_300K_labeling_XXXXX_hpc1.inp , 2_ch3cl_br_close_300K_labeling_XXXXX_hpc2.inp : inputs for CP2K labeling. There are 2 input files per subsystem, see details in labeling . LAMMPS FILES ch3cl_br_close_300K.lmp : starting configurations for the first exploration in the LAMMPS format. ch3cl_br_close_300K.in : inputs for LAMMPS exploration. plumed_SYSTEM_300K.dat : plumed input files for the emplorations. Additional plumed files can be used, and must be named as plumed_KEYWORD_SYSTEM.dat . Here, we used an additional plumed file to store colvars and another to define the key atoms : plumed_colvars_ch3cl_br_close_300K.dat and plumed_atomdef_ch3cl_br_close_300K.dat . The atom order is defined in the properties.txt file. It makes sure that the order of the atoms in the SYSTEM.lmp files match the order indicated in the \"type_map\" keyword of the DeePMD-kit dptrain_2.1.json training file. Also, it makes sure that the generated structures also presents the correct atom numbering to avoid conflicts. Initialization After the initialization step, a default_input.json file is generated, containing the name of the LMP systems found in the user_files/ , and the default number of NNP for training defined in ArcaNN. { \"systems_auto\": [\"ch3br_cl_close_300K\", \"ch3br_cl_free_300K\", \"ch3br_cl_smd_300K\", \"ch3cl_br_close_300K\", \"ch3cl_br_free_300K\", \"ch3cl_br_smd_300K\"], \"nnp_count\": 3 } Training You can now move to the 000-training directory corresponding to the training of the first generation of NNP. After running the prepare phase, a default_input.json file is created. In order to modify some of the default parameters, an input.json file must be created in the same directory, where only the parameters to be updated need to be indicated as the following: { \"user_machine_keyword_train\": \"v100_myproject1\", \"job_walltime_train_h\": 12.0 } Then, the input is updated and stored in the directory as used_input.json : { \"user_machine_keyword_train\": \"v100_myproject1\", \"user_machine_keyword_freeze\": \"v100_myproject1\", \"user_machine_keyword_compress\": \"v100_myproject1\", \"job_email\": \"\", \"use_initial_datasets\": true, \"use_extra_datasets\": false, \"deepmd_model_version\": 2.1, \"job_walltime_train_h\": 12.0, \"mean_s_per_step\": 0.108, \"start_lr\": 0.001, \"stop_lr\": 1e-06, \"decay_rate\": 0.9172759353897796, \"decay_steps\": 5000, \"decay_steps_fixed\": false, \"numb_steps\": 400000, \"numb_test\": 0 } The corresponding control file in your local $WORKDIR/control/ is updated after the execution of each phase . Once the 000-training step is finished, you will find the following training_000.json file: { \"user_machine_keyword_train\": \"v100_myproject1\", \"user_machine_keyword_freeze\": \"v100_myproject1\", \"user_machine_keyword_compress\": \"v100_myproject1\", \"job_email\": \"\", \"use_initial_datasets\": true, \"use_extra_datasets\": false, \"deepmd_model_version\": 2.1, \"job_walltime_train_h\": 12.0, \"mean_s_per_step\": 0.039030916666666665, \"start_lr\": 0.001, \"stop_lr\": 1e-06, \"decay_rate\": 0.9172759353897796, \"decay_steps\": 5000, \"decay_steps_fixed\": false, \"numb_steps\": 400000, \"numb_test\": 0, \"training_datasets\": [\"init_ch3br_cl_xxxxx_1001_4001_60\", \"init_ch3cl_br_xxxxx_1001_4001_60\"], \"trained_count\": 1000, \"initial_count\": 1000, \"added_auto_count\": 0, \"added_adhoc_count\": 0, \"added_auto_iter_count\": 0, \"added_adhoc_iter_count\": 0, \"extra_count\": 0, \"is_prepared\": true, \"is_launched\": true, \"is_checked\": true, \"is_freeze_launched\": true, \"is_frozen\": true, \"is_compress_launched\": true, \"is_compressed\": true, \"is_incremented\": true, \"min_nbor_dist\": 0.9898124626241066, \"max_nbor_size\": [30, 45, 1, 1, 17], \"median_s_per_step\": 0.038560000000000004, \"stdeviation_s_per_step\": 0.0011691332942493009 } When a phase is executed succesfully, the corresponding \"is_prepared\" , \"is_launched\" , \"is_checked\" , etc. keywords are set to true Additional performance data, such as the mean time ( \"mean_s_per_step\" ), median time ( \"median_s_per_step\" ) and standard deviation ( \"stdeviation_s_per_step\" ) per training step are reported in this file. Exploration After the first training phase you now have starting NNP that can be used to propagate reactive MD. After executing the prepare phase in the 0001-exploration/ folder, you will obtain an default_input.json file with default values. We allow for the first exploration for slightly larger deviations by setting \"sigma_low\" keyword set to 0.15 eV/Ang. This is done by modifying the input.json and running prepare again. { \"sigma_low\": 0.15 } The used_input.json becomes then: { \"user_machine_keyword_exp\": \"v100_myproject1\", \"job_email\": \"\", \"atomsk_path\": \"/programs/apps/atomsk/0.13.1/atomsk\", \"vmd_path\": \"/prod/vmd/1.9.4a43/bin/vmd_LINUXAMD64\", \"exploration_type\": [\"lammps\", \"lammps\", \"lammps\", \"lammps\", \"lammps\", \"lammps\"], \"traj_count\": [2, 2, 2, 2, 2, 2], \"temperature_K\": [300.0, 300.0, 300.0, 300.0, 300.0, 300.0], \"timestep_ps\": [0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005], \"previous_start\": [true, true, true, true, true, true], \"disturbed_start\": [false, false, false, false, false, false], \"print_interval_mult\": [0.01, 0.01, 0.01, 0.01, 0.01, 0.01], \"job_walltime_h\": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0], \"exp_time_ps\": [10.0, 10.0, 41.0, 10.0, 10.0, 41.0], \"max_exp_time_ps\": [400, 400, 400, 400, 400, 400], \"max_candidates\": [50, 50, 50, 50, 50, 50], \"sigma_low\": [0.15, 0.15, 0.15, 0.15, 0.15, 0.15], \"sigma_high\": [0.7, 0.7, 0.7, 0.7, 0.7, 0.7], \"sigma_high_limit\": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0], \"ignore_first_x_ps\": [0.5, 0.5, 0.5, 0.5, 0.5, 0.5], \"disturbed_start_value\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0], \"disturbed_start_indexes\": [[], [], [], [], [], []], \"disturbed_candidate_value\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0], \"disturbed_candidate_indexes\": [[], [], [], [], [], []] } For the first iteration the default parameters are a good starting point. The \"traj_count\" keyword sets to 2 the number of simulations per NNP. and per system and \"timestep_ps\" sets to 0.0005 ps the timestep of the simulations. The \"disturbed_candidate_value\" keywords are all set to 0, so no disturbance is applied to the candidate structures that will be added to the training set. To perform the explorations, one directory per system is created, in which there will be 3 subdirectories (one per trained NNP) 1/ , 2/ and 3/ , in which again there will be 2 subdirectories (by default) 0001/ and 0002/ . This means that a total of 36 MD trajectories will be performed for this first iteration. Be careful, the total exploration time can quickly become huge, especially if you have many systems. If we have a look at the exploration_001.json file inside the $WORKDIR/control/ folder: { \"atomsk_path\": \"/programs/apps/atomsk/0.13.1/atomsk\", \"user_machine_keyword_exp\": \"v100_myproject1\", \"deepmd_model_version\": 2.1, \"nnp_count\": 3, \"systems_auto\": { \"ch3br_cl_close_300K\": { // exploration parameters from used_input.json }, \"ch3br_cl_free_300K\": { // }, \"ch3br_cl_smd_300K\": { // }, \"ch3cl_br_close_300K\": { // }, \"ch3cl_br_free_300K\": { // }, \"ch3cl_br_smd_300K\": { // } }, \"is_locked\": true, \"is_launched\": true, \"is_checked\": true, \"is_deviated\": true, \"is_extracted\": true, \"nb_sim\": 36, \"vmd_path\": \"/prod/vmd/1.9.4a43/bin/vmd_LINUXAMD64\" } The total number of MD simulations is indicated by the \"nb_sim\" keyword. The \"vmd_path\" and the \"atomsk_path\" correspond to the ones indicated in the used_input.json , but are not necessary if the code is already available in the ArcaNN path. When the exploration step is succesfully finished, all the phase keywords are set to \"true\" . Labeling For the last step of the first iteration, we move to the $WORKDIR/001-labeling/ folder to run the different phases . You should adapt the Slurm parameters for the electronic structure calculation to match the architecture of your system. In this case, the number of MPI processes per node is set to 16 with the \"nb_mpi_per_node\" keyword in the input.json : { \"user_machine_keyword_label\": \"mykeyword1\", \"nb_mpi_per_node\": 16 } As usual, the used_input.json file will be updated consequently when re running the prepare phase: { \"user_machine_keyword_label\": \"mykeyword1\", \"job_email\": \"\", \"labeling_program\": \"cp2k\", \"walltime_first_job_h\": [0.5, 0.5, 0.5, 0.5, 0.5, 0.5], \"walltime_second_job_h\": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0], \"nb_nodes\": [1, 1, 1, 1, 1, 1], \"nb_mpi_per_node\": [16, 16, 16, 16, 16, 16], \"nb_threads_per_mpi\": [1, 1, 1, 1, 1, 1] } The number of MPI processes hs been set to 16 for the 6 systems. The walltimes of both calculations (2 calculation are performed when using CP2, a first quick calculation at a lower level of theory and then the reference level) are kept at the default values. Here the reactive water calculations use full nodes and have a higher wall time of 1h30min. The wall times should be set for the first iteration but can be guessed automatically later using the average time per CP2K calculation measured in the previous iteration. We can now run the first 2 phases and wait for the electronic structure calculations to finish. When running the check phase there could be a message telling us that there are failed configurations in the water-reactive folder! We can see which calculations did not converge in the water-reactive/water-reactive_step2_not_converged.txt file. Suppose there were 2 failed jobs, the 13-th and the 54-th. We might just do touch water-reactive/00013/skip and touch water-reactive/00054/skip and run the check phase again. This time it will inform us that some configurations will be skipped, but the final message should be that check phase is a success. All that is left to do now is run the extract phase, clean up with the clean phase, store wavefunctions and remove all unwanted data and finally update our local folder. We have now augmented our total training set and might do a new training iteration and keep iterating until convergence is reached! Finally, we can check the labeling_001.json file in $WORKDIR/control/ : { \"labeling_program\": \"cp2k\", \"user_machine_keyword_label\": \"mykeyword1\", \"systems_auto\": { \"ch3br_cl_close_300K\": { // labeling parameters from used_input.json }, \"ch3br_cl_free_300K\": { // }, \"ch3br_cl_smd_300K\": { // }, \"ch3cl_br_close_300K\": { // }, \"ch3cl_br_free_300K\": { // }, \"ch3cl_br_smd_300K\": { } }, \"total_to_label\": 50, \"launch_all_jobs\": true, \"is_locked\": true, \"is_launched\": true, \"is_checked\": true, \"is_extracted\": true } The total number of structures that have been selected labeled from the selected candidates in the previous exploration step is indicated with the \"total_to_label\" keyword. The first iteration is done. After executing the extract phase, the directories for the next iteration will be created.","title":"SN2"},{"location":"examples/sn2/#sn2","text":"Here we introduce the basic usage of the ArcaNN software, ilustrated by a SN2 reaction. All the files are available in the GitHub Repository ; and after ArcaNN installation, you will find them at examples/sn2_ch3cl_br/ inside your local arcann_traininig directory. The iterative training and dataset generation for the SN2 reaction, comprised two iterative trainings : a first non-reactive training was performed on reactant and products structures, followed by a reactive training where transition structures were generated. The files set up for the non-reactive SN2 ArcaNN training is illustrated bellow. Then, the ArcaNN inputs for each step of the first iteration and the corresponding control json files are detailed.","title":"SN2"},{"location":"examples/sn2/#user-files","text":"We will start by creating a user_files/ directory (See Iterative procedure prerequisites ) where we will include the necessary files for each step of the procedure. You also need to create a data/ directory where the initial labeled datasets will be stored. For the reactive training, you will store the datasets of the non-reactive training in the corresponding data/ directory, together with the initial datasets. For the non-reactive training, 6 systems were defined : 3 systems to explore the reactant basin ( ch3cl_br_close_300K , ch3cl_br_free_300K , ch3cl_br_smd_300K ) and 3 systems to explore the product basin ( ch3br_cl_close_300K , ch3br_cl_free_300K , ch3br_cl_smd_300K ). In the user_files/ folder you will find the following files for each one of the systems (for clarity purposes, we only indicate the files of the ch3cl_br_close_300K system here). Note also that hpc1 and hpc2 are the machine keywords indicated in the machine.json file, see HPC Configuration . JSON FILES machine.json : file containing the cluster parameters. dp_train_2.1.json : input for DeePMD trainings. JOB FILES job_lammps-deepmd_explore_gpu_hpc1.sh and job-array_lammps-deepmd_explore_gpu_hpc1.sh : job scripts for exploration job_CP2K_label_cpu_hpc1.sh and job-array_CP2K_label_hpc1.sh : job scripts for labeling job_deepmd_compress_gpu_hpc1.sh , job_deepmd_freeze_gpu_hpc1.sh and job_deepmd_train_gpu_hpc1.sh job scripts for training CP2K FILES 1_ch3cl_br_close_300K_labeling_XXXXX_hpc1.inp , 2_ch3cl_br_close_300K_labeling_XXXXX_hpc1.inp , 1_ch3cl_br_close_300K_labeling_XXXXX_hpc1.inp , 2_ch3cl_br_close_300K_labeling_XXXXX_hpc2.inp : inputs for CP2K labeling. There are 2 input files per subsystem, see details in labeling . LAMMPS FILES ch3cl_br_close_300K.lmp : starting configurations for the first exploration in the LAMMPS format. ch3cl_br_close_300K.in : inputs for LAMMPS exploration. plumed_SYSTEM_300K.dat : plumed input files for the emplorations. Additional plumed files can be used, and must be named as plumed_KEYWORD_SYSTEM.dat . Here, we used an additional plumed file to store colvars and another to define the key atoms : plumed_colvars_ch3cl_br_close_300K.dat and plumed_atomdef_ch3cl_br_close_300K.dat . The atom order is defined in the properties.txt file. It makes sure that the order of the atoms in the SYSTEM.lmp files match the order indicated in the \"type_map\" keyword of the DeePMD-kit dptrain_2.1.json training file. Also, it makes sure that the generated structures also presents the correct atom numbering to avoid conflicts.","title":"User files"},{"location":"examples/sn2/#initialization","text":"After the initialization step, a default_input.json file is generated, containing the name of the LMP systems found in the user_files/ , and the default number of NNP for training defined in ArcaNN. { \"systems_auto\": [\"ch3br_cl_close_300K\", \"ch3br_cl_free_300K\", \"ch3br_cl_smd_300K\", \"ch3cl_br_close_300K\", \"ch3cl_br_free_300K\", \"ch3cl_br_smd_300K\"], \"nnp_count\": 3 }","title":"Initialization"},{"location":"examples/sn2/#training","text":"You can now move to the 000-training directory corresponding to the training of the first generation of NNP. After running the prepare phase, a default_input.json file is created. In order to modify some of the default parameters, an input.json file must be created in the same directory, where only the parameters to be updated need to be indicated as the following: { \"user_machine_keyword_train\": \"v100_myproject1\", \"job_walltime_train_h\": 12.0 } Then, the input is updated and stored in the directory as used_input.json : { \"user_machine_keyword_train\": \"v100_myproject1\", \"user_machine_keyword_freeze\": \"v100_myproject1\", \"user_machine_keyword_compress\": \"v100_myproject1\", \"job_email\": \"\", \"use_initial_datasets\": true, \"use_extra_datasets\": false, \"deepmd_model_version\": 2.1, \"job_walltime_train_h\": 12.0, \"mean_s_per_step\": 0.108, \"start_lr\": 0.001, \"stop_lr\": 1e-06, \"decay_rate\": 0.9172759353897796, \"decay_steps\": 5000, \"decay_steps_fixed\": false, \"numb_steps\": 400000, \"numb_test\": 0 } The corresponding control file in your local $WORKDIR/control/ is updated after the execution of each phase . Once the 000-training step is finished, you will find the following training_000.json file: { \"user_machine_keyword_train\": \"v100_myproject1\", \"user_machine_keyword_freeze\": \"v100_myproject1\", \"user_machine_keyword_compress\": \"v100_myproject1\", \"job_email\": \"\", \"use_initial_datasets\": true, \"use_extra_datasets\": false, \"deepmd_model_version\": 2.1, \"job_walltime_train_h\": 12.0, \"mean_s_per_step\": 0.039030916666666665, \"start_lr\": 0.001, \"stop_lr\": 1e-06, \"decay_rate\": 0.9172759353897796, \"decay_steps\": 5000, \"decay_steps_fixed\": false, \"numb_steps\": 400000, \"numb_test\": 0, \"training_datasets\": [\"init_ch3br_cl_xxxxx_1001_4001_60\", \"init_ch3cl_br_xxxxx_1001_4001_60\"], \"trained_count\": 1000, \"initial_count\": 1000, \"added_auto_count\": 0, \"added_adhoc_count\": 0, \"added_auto_iter_count\": 0, \"added_adhoc_iter_count\": 0, \"extra_count\": 0, \"is_prepared\": true, \"is_launched\": true, \"is_checked\": true, \"is_freeze_launched\": true, \"is_frozen\": true, \"is_compress_launched\": true, \"is_compressed\": true, \"is_incremented\": true, \"min_nbor_dist\": 0.9898124626241066, \"max_nbor_size\": [30, 45, 1, 1, 17], \"median_s_per_step\": 0.038560000000000004, \"stdeviation_s_per_step\": 0.0011691332942493009 } When a phase is executed succesfully, the corresponding \"is_prepared\" , \"is_launched\" , \"is_checked\" , etc. keywords are set to true Additional performance data, such as the mean time ( \"mean_s_per_step\" ), median time ( \"median_s_per_step\" ) and standard deviation ( \"stdeviation_s_per_step\" ) per training step are reported in this file.","title":"Training"},{"location":"examples/sn2/#exploration","text":"After the first training phase you now have starting NNP that can be used to propagate reactive MD. After executing the prepare phase in the 0001-exploration/ folder, you will obtain an default_input.json file with default values. We allow for the first exploration for slightly larger deviations by setting \"sigma_low\" keyword set to 0.15 eV/Ang. This is done by modifying the input.json and running prepare again. { \"sigma_low\": 0.15 } The used_input.json becomes then: { \"user_machine_keyword_exp\": \"v100_myproject1\", \"job_email\": \"\", \"atomsk_path\": \"/programs/apps/atomsk/0.13.1/atomsk\", \"vmd_path\": \"/prod/vmd/1.9.4a43/bin/vmd_LINUXAMD64\", \"exploration_type\": [\"lammps\", \"lammps\", \"lammps\", \"lammps\", \"lammps\", \"lammps\"], \"traj_count\": [2, 2, 2, 2, 2, 2], \"temperature_K\": [300.0, 300.0, 300.0, 300.0, 300.0, 300.0], \"timestep_ps\": [0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005], \"previous_start\": [true, true, true, true, true, true], \"disturbed_start\": [false, false, false, false, false, false], \"print_interval_mult\": [0.01, 0.01, 0.01, 0.01, 0.01, 0.01], \"job_walltime_h\": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0], \"exp_time_ps\": [10.0, 10.0, 41.0, 10.0, 10.0, 41.0], \"max_exp_time_ps\": [400, 400, 400, 400, 400, 400], \"max_candidates\": [50, 50, 50, 50, 50, 50], \"sigma_low\": [0.15, 0.15, 0.15, 0.15, 0.15, 0.15], \"sigma_high\": [0.7, 0.7, 0.7, 0.7, 0.7, 0.7], \"sigma_high_limit\": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0], \"ignore_first_x_ps\": [0.5, 0.5, 0.5, 0.5, 0.5, 0.5], \"disturbed_start_value\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0], \"disturbed_start_indexes\": [[], [], [], [], [], []], \"disturbed_candidate_value\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0], \"disturbed_candidate_indexes\": [[], [], [], [], [], []] } For the first iteration the default parameters are a good starting point. The \"traj_count\" keyword sets to 2 the number of simulations per NNP. and per system and \"timestep_ps\" sets to 0.0005 ps the timestep of the simulations. The \"disturbed_candidate_value\" keywords are all set to 0, so no disturbance is applied to the candidate structures that will be added to the training set. To perform the explorations, one directory per system is created, in which there will be 3 subdirectories (one per trained NNP) 1/ , 2/ and 3/ , in which again there will be 2 subdirectories (by default) 0001/ and 0002/ . This means that a total of 36 MD trajectories will be performed for this first iteration. Be careful, the total exploration time can quickly become huge, especially if you have many systems. If we have a look at the exploration_001.json file inside the $WORKDIR/control/ folder: { \"atomsk_path\": \"/programs/apps/atomsk/0.13.1/atomsk\", \"user_machine_keyword_exp\": \"v100_myproject1\", \"deepmd_model_version\": 2.1, \"nnp_count\": 3, \"systems_auto\": { \"ch3br_cl_close_300K\": { // exploration parameters from used_input.json }, \"ch3br_cl_free_300K\": { // }, \"ch3br_cl_smd_300K\": { // }, \"ch3cl_br_close_300K\": { // }, \"ch3cl_br_free_300K\": { // }, \"ch3cl_br_smd_300K\": { // } }, \"is_locked\": true, \"is_launched\": true, \"is_checked\": true, \"is_deviated\": true, \"is_extracted\": true, \"nb_sim\": 36, \"vmd_path\": \"/prod/vmd/1.9.4a43/bin/vmd_LINUXAMD64\" } The total number of MD simulations is indicated by the \"nb_sim\" keyword. The \"vmd_path\" and the \"atomsk_path\" correspond to the ones indicated in the used_input.json , but are not necessary if the code is already available in the ArcaNN path. When the exploration step is succesfully finished, all the phase keywords are set to \"true\" .","title":"Exploration"},{"location":"examples/sn2/#labeling","text":"For the last step of the first iteration, we move to the $WORKDIR/001-labeling/ folder to run the different phases . You should adapt the Slurm parameters for the electronic structure calculation to match the architecture of your system. In this case, the number of MPI processes per node is set to 16 with the \"nb_mpi_per_node\" keyword in the input.json : { \"user_machine_keyword_label\": \"mykeyword1\", \"nb_mpi_per_node\": 16 } As usual, the used_input.json file will be updated consequently when re running the prepare phase: { \"user_machine_keyword_label\": \"mykeyword1\", \"job_email\": \"\", \"labeling_program\": \"cp2k\", \"walltime_first_job_h\": [0.5, 0.5, 0.5, 0.5, 0.5, 0.5], \"walltime_second_job_h\": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0], \"nb_nodes\": [1, 1, 1, 1, 1, 1], \"nb_mpi_per_node\": [16, 16, 16, 16, 16, 16], \"nb_threads_per_mpi\": [1, 1, 1, 1, 1, 1] } The number of MPI processes hs been set to 16 for the 6 systems. The walltimes of both calculations (2 calculation are performed when using CP2, a first quick calculation at a lower level of theory and then the reference level) are kept at the default values. Here the reactive water calculations use full nodes and have a higher wall time of 1h30min. The wall times should be set for the first iteration but can be guessed automatically later using the average time per CP2K calculation measured in the previous iteration. We can now run the first 2 phases and wait for the electronic structure calculations to finish. When running the check phase there could be a message telling us that there are failed configurations in the water-reactive folder! We can see which calculations did not converge in the water-reactive/water-reactive_step2_not_converged.txt file. Suppose there were 2 failed jobs, the 13-th and the 54-th. We might just do touch water-reactive/00013/skip and touch water-reactive/00054/skip and run the check phase again. This time it will inform us that some configurations will be skipped, but the final message should be that check phase is a success. All that is left to do now is run the extract phase, clean up with the clean phase, store wavefunctions and remove all unwanted data and finally update our local folder. We have now augmented our total training set and might do a new training iteration and keep iterating until convergence is reached! Finally, we can check the labeling_001.json file in $WORKDIR/control/ : { \"labeling_program\": \"cp2k\", \"user_machine_keyword_label\": \"mykeyword1\", \"systems_auto\": { \"ch3br_cl_close_300K\": { // labeling parameters from used_input.json }, \"ch3br_cl_free_300K\": { // }, \"ch3br_cl_smd_300K\": { // }, \"ch3cl_br_close_300K\": { // }, \"ch3cl_br_free_300K\": { // }, \"ch3cl_br_smd_300K\": { } }, \"total_to_label\": 50, \"launch_all_jobs\": true, \"is_locked\": true, \"is_launched\": true, \"is_checked\": true, \"is_extracted\": true } The total number of structures that have been selected labeled from the selected candidates in the previous exploration step is indicated with the \"total_to_label\" keyword. The first iteration is done. After executing the extract phase, the directories for the next iteration will be created.","title":"Labeling"},{"location":"getting-started/hpc_configuration/","text":"HPC Configuration ArcaNN is designed for use on one or several HPC machines, whose specific configurations must be specified by the user through a machine.json file. A general example file can be found in the GitHub Repository . You should modify this file to suit your setup and then copy it to the user_files/ folder in your working directory (see later in Usage ). Structure of the machine.json File The machine.json file is organized as a JSON dictionary with one or more keys that designate different HPC machines. The typical structure looks like this: { \"myHPCkeyword1\": {ENTRIES THAT DESCRIBE HPC 1}, \"myHPCkeyword2\": {ENTRIES THAT DESCRIBE HPC 2}, // Additional machines can be added here } Each key in the JSON file is a short string designating the name of the machine (e.g., \"myHPCkeyword1\" , \"myHPCkeyword2\" are the names of 2 different HPC machines). The value associated with each key is a dictionary indicating the configuration entries for running jobs on the corresponding HPC machine. Below is an example of the initial entries for an HPC machine using a SLURM job scheduler: { \"myHPCkeyword1\": { \"hostname\": \"myHPC1\", \"walltime_format\": \"hours\", \"job_scheduler\": \"slurm\", \"launch_command\": \"sbatch\", \"max_jobs\": 200, \"max_array_size\": 500, \"mykeyword1\": { \"project_name\": \"myproject\", \"allocation_name\": \"myallocationgpu1\", \"arch_name\": \"a100\", \"arch_type\": \"gpu\", \"partition\": \"mypartitiongpu1\", \"subpartition\": \"mysubpartitiongpu1\", \"qos\": { \"myqosgpu1\": 72000, \"myqosgpu2\": 360000 }, \"valid_for\": [\"training\"], \"default\": [\"training\"] }, \"mykeyword2\": { /* Additional partition configurations */ } }, /* Additional HPC machines can be added here */ } HPC Entry Each HPC machine entry contains a JSON directonary where each key corresponds to a configuration entry. hostname : A substring contained in the output of python -c \"import socket ; print(socket.gethostname())\" . This should match your machine's name. walltime_format : The unit of time (e.g., hours) used to specify wall time on the cluster. job_scheduler : The job scheduler used by your HPC machine (e.g., slurm , PBS/Torque ). ArcaNN is extensively tested with Slurm . launch_command : The command for submitting jobs (e.g., sbatch for Slurm , qsub for PBS/Torque ). max_jobs : Maximum number of jobs per user allowed by the scheduler. Can also be a user-defined safety limit. max_array_size : Maximum number of jobs in a single job array. This is important for Slurm as ArcaNN relies heavily on job arrays. Resource Configuration Several resources can be available for calculation within the same HPC machine. Each available resource in the HPC machine is represented by a key (e.g., \"mykeyword1\" ) and includes: project_name : Name of the project using the HPC resources. It will correspond to the _R_PROJECT_ keyword in the #SBATCH --account=_R_PROJECT_ line of the slurm job. allocation_name : Allocation or account name, typically used in large HPC facilities. It will correspond to the _R_ALLOC_ keyword in the #SBATCH --account=_R_PROJECT_@_R_ALLOC_ line of the slurm job. arch_name : Architecture name (e.g., a100 for GPU nodes). arch_type : Architecture type (e.g., gpu or cpu ). partition : The partition on the HPC machine. subpartition : (Optional) Subpartition within the main partition. qos : Quality of Service settings, with corresponding time limits in seconds. valid_for : Specifies the steps this partition is valid for (e.g., [\"training\", \"freezing\", \"compressing\", \"exploration\", \"test\", \"labeling\"] ). default : Indicates the default partition for specific steps. Customization and Submission Files You can add multiple partition configurations as needed. For example, \"mykeyword1\" could represent a GPU partition using A100 GPU nodes, which is used for training unless a different partition is specified. If your HPC setup does not include projects, allocations, partitions, or subpartitions, you can omit the corresponding keywords. To run ArcaNN on your HPC machine, you must provide example submission files tailored to your system. These files should be modeled after the examples/user_files/job*/*.sh files and must include the replaceable strings indicated by a _R_ prefix and suffix. Place these files in the $WORK_DIR/user_files/ folder, which you must create to use ArcaNN for a specific system (see Usage ).","title":"HPC Configuration"},{"location":"getting-started/hpc_configuration/#hpc-configuration","text":"ArcaNN is designed for use on one or several HPC machines, whose specific configurations must be specified by the user through a machine.json file. A general example file can be found in the GitHub Repository . You should modify this file to suit your setup and then copy it to the user_files/ folder in your working directory (see later in Usage ).","title":"HPC Configuration"},{"location":"getting-started/hpc_configuration/#structure-of-the-machinejson-file","text":"The machine.json file is organized as a JSON dictionary with one or more keys that designate different HPC machines. The typical structure looks like this: { \"myHPCkeyword1\": {ENTRIES THAT DESCRIBE HPC 1}, \"myHPCkeyword2\": {ENTRIES THAT DESCRIBE HPC 2}, // Additional machines can be added here } Each key in the JSON file is a short string designating the name of the machine (e.g., \"myHPCkeyword1\" , \"myHPCkeyword2\" are the names of 2 different HPC machines). The value associated with each key is a dictionary indicating the configuration entries for running jobs on the corresponding HPC machine. Below is an example of the initial entries for an HPC machine using a SLURM job scheduler: { \"myHPCkeyword1\": { \"hostname\": \"myHPC1\", \"walltime_format\": \"hours\", \"job_scheduler\": \"slurm\", \"launch_command\": \"sbatch\", \"max_jobs\": 200, \"max_array_size\": 500, \"mykeyword1\": { \"project_name\": \"myproject\", \"allocation_name\": \"myallocationgpu1\", \"arch_name\": \"a100\", \"arch_type\": \"gpu\", \"partition\": \"mypartitiongpu1\", \"subpartition\": \"mysubpartitiongpu1\", \"qos\": { \"myqosgpu1\": 72000, \"myqosgpu2\": 360000 }, \"valid_for\": [\"training\"], \"default\": [\"training\"] }, \"mykeyword2\": { /* Additional partition configurations */ } }, /* Additional HPC machines can be added here */ }","title":"Structure of the machine.json File"},{"location":"getting-started/hpc_configuration/#hpc-entry","text":"Each HPC machine entry contains a JSON directonary where each key corresponds to a configuration entry. hostname : A substring contained in the output of python -c \"import socket ; print(socket.gethostname())\" . This should match your machine's name. walltime_format : The unit of time (e.g., hours) used to specify wall time on the cluster. job_scheduler : The job scheduler used by your HPC machine (e.g., slurm , PBS/Torque ). ArcaNN is extensively tested with Slurm . launch_command : The command for submitting jobs (e.g., sbatch for Slurm , qsub for PBS/Torque ). max_jobs : Maximum number of jobs per user allowed by the scheduler. Can also be a user-defined safety limit. max_array_size : Maximum number of jobs in a single job array. This is important for Slurm as ArcaNN relies heavily on job arrays.","title":"HPC Entry"},{"location":"getting-started/hpc_configuration/#resource-configuration","text":"Several resources can be available for calculation within the same HPC machine. Each available resource in the HPC machine is represented by a key (e.g., \"mykeyword1\" ) and includes: project_name : Name of the project using the HPC resources. It will correspond to the _R_PROJECT_ keyword in the #SBATCH --account=_R_PROJECT_ line of the slurm job. allocation_name : Allocation or account name, typically used in large HPC facilities. It will correspond to the _R_ALLOC_ keyword in the #SBATCH --account=_R_PROJECT_@_R_ALLOC_ line of the slurm job. arch_name : Architecture name (e.g., a100 for GPU nodes). arch_type : Architecture type (e.g., gpu or cpu ). partition : The partition on the HPC machine. subpartition : (Optional) Subpartition within the main partition. qos : Quality of Service settings, with corresponding time limits in seconds. valid_for : Specifies the steps this partition is valid for (e.g., [\"training\", \"freezing\", \"compressing\", \"exploration\", \"test\", \"labeling\"] ). default : Indicates the default partition for specific steps.","title":"Resource Configuration"},{"location":"getting-started/hpc_configuration/#customization-and-submission-files","text":"You can add multiple partition configurations as needed. For example, \"mykeyword1\" could represent a GPU partition using A100 GPU nodes, which is used for training unless a different partition is specified. If your HPC setup does not include projects, allocations, partitions, or subpartitions, you can omit the corresponding keywords. To run ArcaNN on your HPC machine, you must provide example submission files tailored to your system. These files should be modeled after the examples/user_files/job*/*.sh files and must include the replaceable strings indicated by a _R_ prefix and suffix. Place these files in the $WORK_DIR/user_files/ folder, which you must create to use ArcaNN for a specific system (see Usage ).","title":"Customization and Submission Files"},{"location":"getting-started/installation/","text":"ArcaNN Installation Guide Installation on Machines with Internet Access To install ArcaNN , follow these steps: Clone or Download the Repository: Use the green Code button on the repository's main page to either clone or download the repository. While it's recommended to keep a local copy of this repository on any computer that will be used for preparing, running, or analyzing the iterative training process, this is not mandatory. Navigate to the Repository Folder: After downloading or cloning, navigate to the main folder of the repository. Create a Python Environment: Create a new Python environment with all the required packages listed in the tools/arcann_conda_linux-64_env.txt file using the following command: conda create --name <ENVNAME> --file tools/arcann_conda_linux-64_env.txt Activate the Environment and Install the Package: Activate the environment using: conda activate <ENVNAME> Then, install ArcaNN as a Python module: pip install . Verify the Installation: To ensure that ArcaNN has been installed correctly, run the following command: python -m arcann_training --help This command should display the basic usage message of the code. Optional: If you wish, you can delete the repository folder after installation is complete. Note: Alternatively, you can install the program in \"editable\" mode with: pip install -e . This method allows any modifications to the source files to take effect immediately during program execution. It is only recommended if you plan to modify the source files and requires you to keep the repository folder on your machine. Installation on Machines without Internet Access If your machine does not have access to the internet, follow these steps: Download the Repository and Required Files: On a machine with internet access, download the ArcaNN repository. Then, copy the following files into a tmp/ folder (outside of the repository): arcann_training/tools/download_arcann_environment.sh arcann_training/tools/arcann_conda_linux-64_env.txt Download the Required Python Packages: In the tmp/ folder, make the script executable and run it to download all the required Python packages: chmod +x download_arcann_environment.sh ./download_arcann_environment.sh arcann_conda_linux-64_env.txt This script will download all the necessary Python packages into a arcann_conda_linux-64_env_offline_files/ folder and create a arcann_conda_linux-64_env_offline.txt file. Transfer Files to the Offline Machine: Use rsync to transfer the downloaded packages and the ArcaNN repository to your offline machine: rsync -rvu tmp/* USER@WORKMACHINE:/PATH/TO/INSTALLATION/FOLDER/. rsync -rvu arcann_training USER@WORKMACHINE:/PATH/TO/INSTALLATION/FOLDER/. Create the Python Environment on the Offline Machine: On your offline machine, create the required Python environment using the downloaded packages: bash conda create --name <ENVNAME> --file arcann_conda_linux-64_env_offline.txt Install ArcaNN: Finally, install ArcaNN as a Python module by following the installation steps provided earlier: pip install .","title":"ArcaNN Installation Guide"},{"location":"getting-started/installation/#arcann-installation-guide","text":"","title":"ArcaNN Installation Guide"},{"location":"getting-started/installation/#installation-on-machines-with-internet-access","text":"To install ArcaNN , follow these steps: Clone or Download the Repository: Use the green Code button on the repository's main page to either clone or download the repository. While it's recommended to keep a local copy of this repository on any computer that will be used for preparing, running, or analyzing the iterative training process, this is not mandatory. Navigate to the Repository Folder: After downloading or cloning, navigate to the main folder of the repository. Create a Python Environment: Create a new Python environment with all the required packages listed in the tools/arcann_conda_linux-64_env.txt file using the following command: conda create --name <ENVNAME> --file tools/arcann_conda_linux-64_env.txt Activate the Environment and Install the Package: Activate the environment using: conda activate <ENVNAME> Then, install ArcaNN as a Python module: pip install . Verify the Installation: To ensure that ArcaNN has been installed correctly, run the following command: python -m arcann_training --help This command should display the basic usage message of the code. Optional: If you wish, you can delete the repository folder after installation is complete. Note: Alternatively, you can install the program in \"editable\" mode with: pip install -e . This method allows any modifications to the source files to take effect immediately during program execution. It is only recommended if you plan to modify the source files and requires you to keep the repository folder on your machine.","title":"Installation on Machines with Internet Access"},{"location":"getting-started/installation/#installation-on-machines-without-internet-access","text":"If your machine does not have access to the internet, follow these steps: Download the Repository and Required Files: On a machine with internet access, download the ArcaNN repository. Then, copy the following files into a tmp/ folder (outside of the repository): arcann_training/tools/download_arcann_environment.sh arcann_training/tools/arcann_conda_linux-64_env.txt Download the Required Python Packages: In the tmp/ folder, make the script executable and run it to download all the required Python packages: chmod +x download_arcann_environment.sh ./download_arcann_environment.sh arcann_conda_linux-64_env.txt This script will download all the necessary Python packages into a arcann_conda_linux-64_env_offline_files/ folder and create a arcann_conda_linux-64_env_offline.txt file. Transfer Files to the Offline Machine: Use rsync to transfer the downloaded packages and the ArcaNN repository to your offline machine: rsync -rvu tmp/* USER@WORKMACHINE:/PATH/TO/INSTALLATION/FOLDER/. rsync -rvu arcann_training USER@WORKMACHINE:/PATH/TO/INSTALLATION/FOLDER/. Create the Python Environment on the Offline Machine: On your offline machine, create the required Python environment using the downloaded packages: bash conda create --name <ENVNAME> --file arcann_conda_linux-64_env_offline.txt Install ArcaNN: Finally, install ArcaNN as a Python module by following the installation steps provided earlier: pip install .","title":"Installation on Machines without Internet Access"},{"location":"getting-started/requirements/","text":"ArcaNN Requirements Installation Requirements To install and run the software, ensure the following dependencies are installed: Python : >= 3.10 Pip : >= 21.3 Setuptools : >= 60.0 Wheel : >= 0.37 NumPy : >= 1.22 External Programs for Trajectories/Structures Manipulation ArcaNN requires the following external programs for manipulating trajectories and structures: VMD : >= 1.9.3 Atomsk : >= b0.12.2 Supported Programs by Workflow Step Different steps in the workflow are supported by specific programs: DeePMD-kit : >= 2.0 (Used in training and testing steps) LAMMPS : Must be compatible with DeePMD-kit (Used in exploration ) i-PI : Must be compatible with DeePMD-kit (Used in exploration ) PLUMED : Must be compatible with DeePMD-kit (Used in exploration ) CP2K : >= 6.1 (Used in the labeling step)","title":"ArcaNN Requirements"},{"location":"getting-started/requirements/#arcann-requirements","text":"","title":"ArcaNN Requirements"},{"location":"getting-started/requirements/#installation-requirements","text":"To install and run the software, ensure the following dependencies are installed: Python : >= 3.10 Pip : >= 21.3 Setuptools : >= 60.0 Wheel : >= 0.37 NumPy : >= 1.22","title":"Installation Requirements"},{"location":"getting-started/requirements/#external-programs-for-trajectoriesstructures-manipulation","text":"ArcaNN requires the following external programs for manipulating trajectories and structures: VMD : >= 1.9.3 Atomsk : >= b0.12.2","title":"External Programs for Trajectories/Structures Manipulation"},{"location":"getting-started/requirements/#supported-programs-by-workflow-step","text":"Different steps in the workflow are supported by specific programs: DeePMD-kit : >= 2.0 (Used in training and testing steps) LAMMPS : Must be compatible with DeePMD-kit (Used in exploration ) i-PI : Must be compatible with DeePMD-kit (Used in exploration ) PLUMED : Must be compatible with DeePMD-kit (Used in exploration ) CP2K : >= 6.1 (Used in the labeling step)","title":"Supported Programs by Workflow Step"},{"location":"project_details/acknowledgments/","text":"Stackoverflow Beta-testers Olaia Anton, Zakarya Benayad, Miguel de la Puente, Axel Gomez Oscar Gayraud, Pierre Girard, Anne Milet Meritxell Malagarriga Perez, Adri\u00e1n Garc\u00eda Ashley Borkowski, Pauf Neupane, Ward Thompson Hadi Dinpajooh Atomsk Hirel, P. Atomsk: A Tool for Manipulating and Converting Atomic Data Files. Comput. Phys. Commun. 2015, 197, 212\u2013219. https://doi.org/10.1016/j.cpc.2015.07.012 . VMD Humphrey, W.; Dalke, A.; Schulten, K. VMD: Visual Molecular Dynamics. J. Mol. Graph. 1996, 14 (1), 33\u201338. https://doi.org/10.1016/0263-7855(96)00018-5 . DeePMD-kit Zeng, J.; Zhang, D.; Lu, D.; Mo, P.; Li, Z.; Chen, Y.; Rynik, M.; Huang, L.; Li, Z.; Shi, S.; Wang, Y.; Ye, H.; Tuo, P.; Yang, J.; Ding, Y.; Li, Y.; Tisi, D.; Zeng, Q.; Bao, H.; Xia, Y.; Huang, J.; Muraoka, K.; Wang, Y.; Chang, J.; Yuan, F.; Bore, S. L.; Cai, C.; Lin, Y.; Wang, B.; Xu, J.; Zhu, J.-X.; Luo, C.; Zhang, Y.; Goodall, R. E. A.; Liang, W.; Singh, A. K.; Yao, S.; Zhang, J.; Wentzcovitch, R.; Han, J.; Liu, J.; Jia, W.; York, D. M.; E, W.; Car, R.; Zhang, L.; Wang, H. DeePMD-Kit v2: A Software Package for Deep Potential Models. J. Chem. Phys. 2023, 159 (5), 054801. https://doi.org/10.1103/PhysRevMaterials.3.023804 . Wang, H.; Zhang, L.; Han, J.; E, W. DeePMD-Kit: A Deep Learning Package for Many-Body Potential Energy Representation and Molecular Dynamics. Comput. Phys. Commun. 2018, 228, 178\u2013184. https://doi.org/10.1016/j.cpc.2018.03.016 . DP-Compress Lu, D.; Jiang, W.; Chen, Y.; Zhang, L.; Jia, W.; Wang, H.; Chen, M. DP Compress: A Model Compression Scheme for Generating Efficient Deep Potential Models. J. Chem. Theory Comput. 2022, 18 (9), 5559\u20135567. https://doi.org/10.1021/acs.jctc.2c00102 . Concurrent Learning Zhang, L.; Lin, D.-Y.; Wang, H.; Car, R.; E, W. Active Learning of Uniformly Accurate Interatomic Potentials for Materials Simulation. Phys. Rev. Materials 2019, 3 (2), 023804. https://doi.org/10.1103/PhysRevMaterials.3.023804 Zhang, Y.; Wang, H.; Chen, W.; Zeng, J.; Zhang, L.; Wang, H.; E, W. DP-GEN: A Concurrent Learning Platform for the Generation of Reliable Deep Learning Based Potential Energy Models. Comput. Phys. Commun. 2020, 253, 107206. https://doi.org/10.1016/j.cpc.2020.107206 . LAMMPS Thompson, A. P.; Aktulga, H. M.; Berger, R.; Bolintineanu, D. S.; Brown, W. M.; Crozier, P. S.; In \u2019T Veld, P. J.; Kohlmeyer, A.; Moore, S. G.; Nguyen, T. D.; Shan, R.; Stevens, M. J.; Tranchida, J.; Trott, C.; Plimpton, S. J. LAMMPS - a Flexible Simulation Tool for Particle-Based Materials Modeling at the Atomic, Meso, and Continuum Scales. Comput. Phys. Commun. 2022, 271, 108171. https://doi.org/10.1016/j.cpc.2021.108171 . i-PI Kapil, V.; Rossi, M.; Marsalek, O.; Petraglia, R.; Litman, Y.; Spura, T.; Cheng, B.; Cuzzocrea, A.; Mei\u00dfner, R. H.; Wilkins, D. M.; Helfrecht, B. A.; Juda, P.; Bienvenue, S. P.; Fang, W.; Kessler, J.; Poltavsky, I.; Vandenbrande, S.; Wieme, J.; Corminboeuf, C.; K\u00fchne, T. D.; Manolopoulos, D. E.; Markland, T. E.; Richardson, J. O.; Tkatchenko, A.; Tribello, G. A.; Van Speybroeck, V.; Ceriotti, M. I-PI 2.0: A Universal Force Engine for Advanced Molecular Simulations. Comput. Phys. Commun. 2019, 236, 214\u2013223. https://doi.org/10.1016/j.cpc.2018.09.020 . CP2K K\u00fchne, T. D.; Iannuzzi, M.; Del Ben, M.; Rybkin, V. V.; Seewald, P.; Stein, F.; Laino, T.; Khaliullin, R. Z.; Sch\u00fctt, O.; Schiffmann, F.; Golze, D.; Wilhelm, J.; Chulkov, S.; Bani-Hashemian, M. H.; Weber, V.; Bor\u0161tnik, U.; Taillefumier, M.; Jakobovits, A. S.; Lazzaro, A.; Pabst, H.; M\u00fcller, T.; Schade, R.; Guidon, M.; Andermatt, S.; Holmberg, N.; Schenter, G. K.; Hehn, A.; Bussy, A.; Belleflamme, F.; Tabacchi, G.; Gl\u00f6\u00df, A.; Lass, M.; Bethune, I.; Mundy, C. J.; Plessl, C.; Watkins, M.; VandeVondele, J.; Krack, M.; Hutter, J. CP2K: An Electronic Structure and Molecular Dynamics Software Package - Quickstep: Efficient and Accurate Electronic Structure Calculations. J. Chem. Phys. 2020, 152 (19), 194103. https://doi.org/10.1063/5.0007045 .","title":"Acknowledgments"},{"location":"project_details/acknowledgments/#beta-testers","text":"Olaia Anton, Zakarya Benayad, Miguel de la Puente, Axel Gomez Oscar Gayraud, Pierre Girard, Anne Milet Meritxell Malagarriga Perez, Adri\u00e1n Garc\u00eda Ashley Borkowski, Pauf Neupane, Ward Thompson Hadi Dinpajooh","title":"Beta-testers"},{"location":"project_details/acknowledgments/#atomsk","text":"Hirel, P. Atomsk: A Tool for Manipulating and Converting Atomic Data Files. Comput. Phys. Commun. 2015, 197, 212\u2013219. https://doi.org/10.1016/j.cpc.2015.07.012 .","title":"Atomsk"},{"location":"project_details/acknowledgments/#vmd","text":"Humphrey, W.; Dalke, A.; Schulten, K. VMD: Visual Molecular Dynamics. J. Mol. Graph. 1996, 14 (1), 33\u201338. https://doi.org/10.1016/0263-7855(96)00018-5 .","title":"VMD"},{"location":"project_details/acknowledgments/#deepmd-kit","text":"Zeng, J.; Zhang, D.; Lu, D.; Mo, P.; Li, Z.; Chen, Y.; Rynik, M.; Huang, L.; Li, Z.; Shi, S.; Wang, Y.; Ye, H.; Tuo, P.; Yang, J.; Ding, Y.; Li, Y.; Tisi, D.; Zeng, Q.; Bao, H.; Xia, Y.; Huang, J.; Muraoka, K.; Wang, Y.; Chang, J.; Yuan, F.; Bore, S. L.; Cai, C.; Lin, Y.; Wang, B.; Xu, J.; Zhu, J.-X.; Luo, C.; Zhang, Y.; Goodall, R. E. A.; Liang, W.; Singh, A. K.; Yao, S.; Zhang, J.; Wentzcovitch, R.; Han, J.; Liu, J.; Jia, W.; York, D. M.; E, W.; Car, R.; Zhang, L.; Wang, H. DeePMD-Kit v2: A Software Package for Deep Potential Models. J. Chem. Phys. 2023, 159 (5), 054801. https://doi.org/10.1103/PhysRevMaterials.3.023804 . Wang, H.; Zhang, L.; Han, J.; E, W. DeePMD-Kit: A Deep Learning Package for Many-Body Potential Energy Representation and Molecular Dynamics. Comput. Phys. Commun. 2018, 228, 178\u2013184. https://doi.org/10.1016/j.cpc.2018.03.016 .","title":"DeePMD-kit"},{"location":"project_details/acknowledgments/#dp-compress","text":"Lu, D.; Jiang, W.; Chen, Y.; Zhang, L.; Jia, W.; Wang, H.; Chen, M. DP Compress: A Model Compression Scheme for Generating Efficient Deep Potential Models. J. Chem. Theory Comput. 2022, 18 (9), 5559\u20135567. https://doi.org/10.1021/acs.jctc.2c00102 .","title":"DP-Compress"},{"location":"project_details/acknowledgments/#concurrent-learning","text":"Zhang, L.; Lin, D.-Y.; Wang, H.; Car, R.; E, W. Active Learning of Uniformly Accurate Interatomic Potentials for Materials Simulation. Phys. Rev. Materials 2019, 3 (2), 023804. https://doi.org/10.1103/PhysRevMaterials.3.023804 Zhang, Y.; Wang, H.; Chen, W.; Zeng, J.; Zhang, L.; Wang, H.; E, W. DP-GEN: A Concurrent Learning Platform for the Generation of Reliable Deep Learning Based Potential Energy Models. Comput. Phys. Commun. 2020, 253, 107206. https://doi.org/10.1016/j.cpc.2020.107206 .","title":"Concurrent Learning"},{"location":"project_details/acknowledgments/#lammps","text":"Thompson, A. P.; Aktulga, H. M.; Berger, R.; Bolintineanu, D. S.; Brown, W. M.; Crozier, P. S.; In \u2019T Veld, P. J.; Kohlmeyer, A.; Moore, S. G.; Nguyen, T. D.; Shan, R.; Stevens, M. J.; Tranchida, J.; Trott, C.; Plimpton, S. J. LAMMPS - a Flexible Simulation Tool for Particle-Based Materials Modeling at the Atomic, Meso, and Continuum Scales. Comput. Phys. Commun. 2022, 271, 108171. https://doi.org/10.1016/j.cpc.2021.108171 .","title":"LAMMPS"},{"location":"project_details/acknowledgments/#i-pi","text":"Kapil, V.; Rossi, M.; Marsalek, O.; Petraglia, R.; Litman, Y.; Spura, T.; Cheng, B.; Cuzzocrea, A.; Mei\u00dfner, R. H.; Wilkins, D. M.; Helfrecht, B. A.; Juda, P.; Bienvenue, S. P.; Fang, W.; Kessler, J.; Poltavsky, I.; Vandenbrande, S.; Wieme, J.; Corminboeuf, C.; K\u00fchne, T. D.; Manolopoulos, D. E.; Markland, T. E.; Richardson, J. O.; Tkatchenko, A.; Tribello, G. A.; Van Speybroeck, V.; Ceriotti, M. I-PI 2.0: A Universal Force Engine for Advanced Molecular Simulations. Comput. Phys. Commun. 2019, 236, 214\u2013223. https://doi.org/10.1016/j.cpc.2018.09.020 .","title":"i-PI"},{"location":"project_details/acknowledgments/#cp2k","text":"K\u00fchne, T. D.; Iannuzzi, M.; Del Ben, M.; Rybkin, V. V.; Seewald, P.; Stein, F.; Laino, T.; Khaliullin, R. Z.; Sch\u00fctt, O.; Schiffmann, F.; Golze, D.; Wilhelm, J.; Chulkov, S.; Bani-Hashemian, M. H.; Weber, V.; Bor\u0161tnik, U.; Taillefumier, M.; Jakobovits, A. S.; Lazzaro, A.; Pabst, H.; M\u00fcller, T.; Schade, R.; Guidon, M.; Andermatt, S.; Holmberg, N.; Schenter, G. K.; Hehn, A.; Bussy, A.; Belleflamme, F.; Tabacchi, G.; Gl\u00f6\u00df, A.; Lass, M.; Bethune, I.; Mundy, C. J.; Plessl, C.; Watkins, M.; VandeVondele, J.; Krack, M.; Hutter, J. CP2K: An Electronic Structure and Molecular Dynamics Software Package - Quickstep: Efficient and Accurate Electronic Structure Calculations. J. Chem. Phys. 2020, 152 (19), 194103. https://doi.org/10.1063/5.0007045 .","title":"CP2K"},{"location":"project_details/authors/","text":"To cite ArcaNN, please use: David, R.; de la Puente, M.; Gomez, A.; Anton, O.; Stirnemann, G.; Laage, D. ArcaNN: automated enhanced sampling generation of training sets for chemically reactive machine learning interatomic potentials. Digital Discovery, 2024, DOI: 10.1039/D4DD00209A .","title":"Authors"},{"location":"project_details/funding/","text":"Idex ANR-10-IDEX-0001-02PSL ERC Grant Agreement No. 757111 GENCI Grant 2023-A0130707156","title":"Funding"},{"location":"project_details/license/","text":"Distributed under the GNU Affero General Public License v3.0. See LICENSE for more information.","title":"License"},{"location":"usage/exploration/","text":"Exploration In the exploration phase we will generate new configurations (referred to as candidates ) to include in the training set. For this we will perform MD simulations with either the LAMMPS (classical nuclei) or i-PI (quantum nuclei) softwares. Go to the current iteration exploration folder XXX-exploration created at the end of the previous training phase and execute the prepare phase to initialize the exploration. For the first exploration phase we might want to generate only a few candidate configurations to check whether our initial NNP are stable enough to give physically meaningful configurations. We might as well want to use a relatively strict error criterion for candidate selection. To change these parameters you can create a input.json file , indicating the values to be updated, and run the prepare phase again. If you want to keep the default values you only need to run the prepare phase once. As for the Initialization and Training steps, this will generate a used_input.json file: { \"step_name\": \"exploration\", \"user_machine_keyword_exp\": \"mykeyword1\", \"slurm_email\": \"\", \"atomsk_path\": \"PATH_TO_THE_ATOMSK_BINARY\", \"vmd_path\": \"PATH_TO_THE_VMD_BINARY\", \"exploration_type\": [\"lammps\", \"lammps\", \"lammps\"], \"traj_count\": [2, 2, 2], \"temperature_K\": [273.0, 300.0, 300.0], \"timestep_ps\": [0.0005, 0.0005, 0.0005], \"previous_start\": [true, true, true], \"disturbed_start\": [false, false, false], \"print_interval_mult\": [0.01, 0.01, 0.01], \"job_walltime_h\": [-1, -1, -1], \"exp_time_ps\": [10, 10, 10], \"max_exp_time_ps\": [400, 400, 400], \"max_candidates\": [50, 50, 100], \"sigma_low\": [0.1, 0.1, 0.1], \"sigma_high\": [0.8, 0.8, 0.8], \"sigma_high_limit\": [1.5, 1.5, 1.5], \"ignore_first_x_ps\": [0.5, 0.5, 0.5], \"init_exp_time_ps\": [-1, -1, -1], \"init_job_walltime_h\": [-1, -1, -1], \"disturbed_candidate_value\": [0.5, 0, 0], \"disturbed_start_value\": [0.0, 0.0, 0.0], \"disturbed_start_indexes\": [[], [], []], \"disturbed_candidate_indexes\": [[], [], []] } The \"sigma_low\" , \"sigma_high\" and \"sigma_high_limit\" keywords indicate the deviation acceptance criteria in eV/Ang for the candidate selection. The \"max_candidates\" keywords indicates the maximum candidated that can be selected. The values in disturbed_start_value are used to disturb the starting structures for the next iteration. A non-zero value sets the maximal amplitude of the random translation vector that will be applied to each atom (a different vector for each atom) in \u00c5. Note: the vmd_path keyword is not needed if vmd is inmediately available in our path when executing the extract phase (loaded as a module for example). Similarly, we can remove atomsk_path if atomsk is already in the path. Some of the phases are slightly different if you use LAMMPS or i-PI, both phase workflows are detailed below. LAMMPS: classical nuclei simulations Once you are satisfied with your exploration parameters (see example below) you can execute the next exploration phases : launch to run MD trajectories with each subsystem and check (once the Slurm MD jobs are done!). If the check phase is succesfull, you can move on to the deviate phase, where you can set important parameters for candidate selection. Once again you can modify these keywors by the creation (or modification if you already created one for a previous phase) of a default_input.json file and re-executing the deviate phase. In the extract phase an important choice can be made: whether to include \"disturbed\" candidates in the training set or not. This is done by changing the disturbed_start_value and disturbed_candidate_value variables from the defaults (0.0) and will include a set of candidates generated by applying a random perturbation to those obtained in the MD trajectories (this will multiply by 2 the number of selected candidates, make sure that the disturbed_start_value that you choose will still give physically meaningful configurations, otherwise you will deteriorate your NNP!). Once you execute this phase a candidates_SUBSYS_XXX.xyz file will be created in each subsystem directory containing the candidate configurations that will be added to the training set (you might want to check that they make sense!). You can also disturb only some atoms in the configuration in which case you will need to write their (zero-based) atomic indices in the disturbed_candidate_indexes variable. The clean phase can be executed to clean up all the temporary files. A control/exploration_XXX.json file will be written recording all the exploration parameters. You can now move on to the labeling phase! (Don't forget to keep your local folder updated so that you can analyze all these results) i-PI quantum nuclei simulations Simulations explicitly including nuclear quantum effects by path-integral molecular dynamics with i-PI are quite similar to classical nuclei simulations with LAMMPS. Although the i-PI input files are different (see i-PI ), the prepare , launch and check phases can be done exactly as previously (see LAMMPS classical nuclei simulations above). Then, before executing the deviate and extract phases, you must run select_beads and rerun in this order. These phases do not have special parameters that need to be tuned but require VMD and Atomsk . After that, you can run the rest of the steps as for LAMMPS MD simulations.","title":"Exploration"},{"location":"usage/exploration/#exploration","text":"In the exploration phase we will generate new configurations (referred to as candidates ) to include in the training set. For this we will perform MD simulations with either the LAMMPS (classical nuclei) or i-PI (quantum nuclei) softwares. Go to the current iteration exploration folder XXX-exploration created at the end of the previous training phase and execute the prepare phase to initialize the exploration. For the first exploration phase we might want to generate only a few candidate configurations to check whether our initial NNP are stable enough to give physically meaningful configurations. We might as well want to use a relatively strict error criterion for candidate selection. To change these parameters you can create a input.json file , indicating the values to be updated, and run the prepare phase again. If you want to keep the default values you only need to run the prepare phase once. As for the Initialization and Training steps, this will generate a used_input.json file: { \"step_name\": \"exploration\", \"user_machine_keyword_exp\": \"mykeyword1\", \"slurm_email\": \"\", \"atomsk_path\": \"PATH_TO_THE_ATOMSK_BINARY\", \"vmd_path\": \"PATH_TO_THE_VMD_BINARY\", \"exploration_type\": [\"lammps\", \"lammps\", \"lammps\"], \"traj_count\": [2, 2, 2], \"temperature_K\": [273.0, 300.0, 300.0], \"timestep_ps\": [0.0005, 0.0005, 0.0005], \"previous_start\": [true, true, true], \"disturbed_start\": [false, false, false], \"print_interval_mult\": [0.01, 0.01, 0.01], \"job_walltime_h\": [-1, -1, -1], \"exp_time_ps\": [10, 10, 10], \"max_exp_time_ps\": [400, 400, 400], \"max_candidates\": [50, 50, 100], \"sigma_low\": [0.1, 0.1, 0.1], \"sigma_high\": [0.8, 0.8, 0.8], \"sigma_high_limit\": [1.5, 1.5, 1.5], \"ignore_first_x_ps\": [0.5, 0.5, 0.5], \"init_exp_time_ps\": [-1, -1, -1], \"init_job_walltime_h\": [-1, -1, -1], \"disturbed_candidate_value\": [0.5, 0, 0], \"disturbed_start_value\": [0.0, 0.0, 0.0], \"disturbed_start_indexes\": [[], [], []], \"disturbed_candidate_indexes\": [[], [], []] } The \"sigma_low\" , \"sigma_high\" and \"sigma_high_limit\" keywords indicate the deviation acceptance criteria in eV/Ang for the candidate selection. The \"max_candidates\" keywords indicates the maximum candidated that can be selected. The values in disturbed_start_value are used to disturb the starting structures for the next iteration. A non-zero value sets the maximal amplitude of the random translation vector that will be applied to each atom (a different vector for each atom) in \u00c5. Note: the vmd_path keyword is not needed if vmd is inmediately available in our path when executing the extract phase (loaded as a module for example). Similarly, we can remove atomsk_path if atomsk is already in the path. Some of the phases are slightly different if you use LAMMPS or i-PI, both phase workflows are detailed below.","title":"Exploration"},{"location":"usage/exploration/#lammps-classical-nuclei-simulations","text":"Once you are satisfied with your exploration parameters (see example below) you can execute the next exploration phases : launch to run MD trajectories with each subsystem and check (once the Slurm MD jobs are done!). If the check phase is succesfull, you can move on to the deviate phase, where you can set important parameters for candidate selection. Once again you can modify these keywors by the creation (or modification if you already created one for a previous phase) of a default_input.json file and re-executing the deviate phase. In the extract phase an important choice can be made: whether to include \"disturbed\" candidates in the training set or not. This is done by changing the disturbed_start_value and disturbed_candidate_value variables from the defaults (0.0) and will include a set of candidates generated by applying a random perturbation to those obtained in the MD trajectories (this will multiply by 2 the number of selected candidates, make sure that the disturbed_start_value that you choose will still give physically meaningful configurations, otherwise you will deteriorate your NNP!). Once you execute this phase a candidates_SUBSYS_XXX.xyz file will be created in each subsystem directory containing the candidate configurations that will be added to the training set (you might want to check that they make sense!). You can also disturb only some atoms in the configuration in which case you will need to write their (zero-based) atomic indices in the disturbed_candidate_indexes variable. The clean phase can be executed to clean up all the temporary files. A control/exploration_XXX.json file will be written recording all the exploration parameters. You can now move on to the labeling phase! (Don't forget to keep your local folder updated so that you can analyze all these results)","title":"LAMMPS: classical nuclei simulations"},{"location":"usage/exploration/#i-pi-quantum-nuclei-simulations","text":"Simulations explicitly including nuclear quantum effects by path-integral molecular dynamics with i-PI are quite similar to classical nuclei simulations with LAMMPS. Although the i-PI input files are different (see i-PI ), the prepare , launch and check phases can be done exactly as previously (see LAMMPS classical nuclei simulations above). Then, before executing the deviate and extract phases, you must run select_beads and rerun in this order. These phases do not have special parameters that need to be tuned but require VMD and Atomsk . After that, you can run the rest of the steps as for LAMMPS MD simulations.","title":"i-PI quantum nuclei simulations"},{"location":"usage/initialization/","text":"Initialization Now that you have decided the subsystems that you want to train your NNP on and prepared all the required files you can initialize the ArcaNN procedure by running (from the $WORK_DIR folder): python -m arcann_training initialization start Now it should have generated your first 000-training directory. In $WORK_DIR you will also find a default_input.json file that lools like this : { \"step_name\": \"initialization\", \"systems_auto\": [\"SYSNAME1\", \"SYSNAME2\", \"SYSNAME3\"], \"nnp_count\": 3 } The \"systems_auto\" keyword contains the name of all the systems that were found in your $WORK_DIR/user_files/ (i.e. all LMP files) directory and \"nnp_count\" is the number of NNP that is used by default in the committee. The initialization will create several folders. The most important one is the control/ folder, in which essential data files will be stored throughout the iterative procedure. These files will be written in .json format and should NOT be modified. Right after initialization the only file in control/ is config.json , which contains the essential information about your initialization choices (or defaults), such as your subsystem names and options. Finally the 000-training empty folder should also have been created by the execution of the python script, where you will perform the first iteration of training . If at this point you want to modify the datasets used for the first training you simply have to create an input.json from the default_input.json file and remove or add the system names to the list. You could also change the number of NNP if you wish. Then you only have have to execute the command of the initialization phase again and your 000-training directory will be updated.","title":"Initialization"},{"location":"usage/initialization/#initialization","text":"Now that you have decided the subsystems that you want to train your NNP on and prepared all the required files you can initialize the ArcaNN procedure by running (from the $WORK_DIR folder): python -m arcann_training initialization start Now it should have generated your first 000-training directory. In $WORK_DIR you will also find a default_input.json file that lools like this : { \"step_name\": \"initialization\", \"systems_auto\": [\"SYSNAME1\", \"SYSNAME2\", \"SYSNAME3\"], \"nnp_count\": 3 } The \"systems_auto\" keyword contains the name of all the systems that were found in your $WORK_DIR/user_files/ (i.e. all LMP files) directory and \"nnp_count\" is the number of NNP that is used by default in the committee. The initialization will create several folders. The most important one is the control/ folder, in which essential data files will be stored throughout the iterative procedure. These files will be written in .json format and should NOT be modified. Right after initialization the only file in control/ is config.json , which contains the essential information about your initialization choices (or defaults), such as your subsystem names and options. Finally the 000-training empty folder should also have been created by the execution of the python script, where you will perform the first iteration of training . If at this point you want to modify the datasets used for the first training you simply have to create an input.json from the default_input.json file and remove or add the system names to the list. You could also change the number of NNP if you wish. Then you only have have to execute the command of the initialization phase again and your 000-training directory will be updated.","title":"Initialization"},{"location":"usage/iter_prerequisites/","text":"Iterative procedure prerequisites When training a neural network potential (NNP) for a chemical system (or several systems that you want to describe with the same NNP), you will often want to explore the chemical space as diversely as possible. In ArcaNN, this is made possible by the use of systems . A system corresponds to a particular way of exploring the chemical space that interests you and will be represented by specific datasets within the total training set of the NNP. A dataset corresponds to an ensemble of structures ( e.g. , atomic positions, types of atoms, box size, etc.) and corresponding labels ( e.g. , energy, forces, virial). You get the idea: you need a subsystem for every kind of chemical composition, physical state (temperature, density, pressure, cell size, etc.), biased reactive pathway, and more that you wish to include in your final training dataset . Attention , systems are defined once and for all in the Initialization of the procedure. Because of this, every time you want to include a new subsystem (such as transition state structures, see SN2 example), you will need to initialize the procedure again. This is very simple\u2014you only need to create a new $WORK_DIR and include the necessary files in user_files/ for each extra system you want to add. To initiate the iterative training procedure, you should create in your $WORK_DIR two folders: user_files/ and data/ . In user_files/ you will store all the files needed for each step. You can find some templates to start with in the GitHub Repository , now available in your machine at your ArcaNN installation location arcann_training/examples/user_files/ . For the exploration step, you must adapt the template files found in exploration_lammps/ or exploration_sander_emle/ depending of your choice. You will need the following files: The input files: SYSTEM.in for LAMMPS and SYSTEM.xml for i-PI. The plumed files: plumed_SYSTEM.dat where SYSNAME refers to the system name (additional PLUMED files can be used as plumed_*_SYSNAME.dat , which will also be taken into account for explorations). For the labeling step, use the template files found in labeling_cp2k/ or labeling_orca/ . You will need the following files: The input files : [1-2]_SYSNAME_labeling_XXXXX_[cluster].inp , where [cluster] refers to the short string selected for the labeling cluster in the machine.json ; see Labeling . For the training step, from training_deepmd you will need: A DeePMD-kit JSON file named dptrain_VERSION.json , where VERSION is the DeePMD-kit version that you will use ( e.g. , 2.1 ; currently supported versions are 2.0 , 2.1 , 2.2 , and 3.0 ). The SLURM scripts for individual jobs and for job arrays are organised by step in several fordels. Prepare your files according to your software choice for each step. You can fin them in: job_exploration_lammps_slurm and job_exploration_sander_emle_slurm for exploration. job_labeling_orca_slurm and job_labeling_cp2k_slurm for the labeling. job_training_deepmd_slurm for training. job_test_deepmd_slurm for testing. We strongly advise you to create the previous files starting from the templates, as they contain replaceable strings for the key parameters that will be updated by the procedure. A representative file in the LAMMPS Data Format format for each system , named SYSTEM.lmp , where SYSTEM refers to the system name (we will refer to them as LMP files). This file represent the configuration of the system , with the number of atoms and the number of types of atoms, the simulation cell dimension, the atomic masses for each type and the atomic geometry of your system . They will be used as starting point for the first exploration. The order of the atoms in the LMP files must be identical for every system and must match the order indicated in the \"type_map\" keyword of the DeePMD-kit dptrain_VERSION.json training file. A properties file must be provided and named properties.txt . This is file will be used by atomsk . In the case you have several systems with different chemical composition, the properties file must be the same for all systems to ensure consistant type mapping. Then, gather all these files and store them inside the user_files/ directory. Don't create subdirectories inside user_files . Finally, you also need to prepare at least one initial dataset which will be used for your first neural networks training, that you will store in the data/ directory. It must follow DeePMD-kit standards and should contain a type.raw file and set.000/ folder with box.npy , coord.npy , energy.npy and force.npy (see DeePMD-kit documentation ). You can prepare as many initial datasets as you wish and they should all be stored in the $WORK_DIR/data/ folder with a folder name starting with init_ .","title":"Iterative procedure prerequisites"},{"location":"usage/iter_prerequisites/#iterative-procedure-prerequisites","text":"When training a neural network potential (NNP) for a chemical system (or several systems that you want to describe with the same NNP), you will often want to explore the chemical space as diversely as possible. In ArcaNN, this is made possible by the use of systems . A system corresponds to a particular way of exploring the chemical space that interests you and will be represented by specific datasets within the total training set of the NNP. A dataset corresponds to an ensemble of structures ( e.g. , atomic positions, types of atoms, box size, etc.) and corresponding labels ( e.g. , energy, forces, virial). You get the idea: you need a subsystem for every kind of chemical composition, physical state (temperature, density, pressure, cell size, etc.), biased reactive pathway, and more that you wish to include in your final training dataset . Attention , systems are defined once and for all in the Initialization of the procedure. Because of this, every time you want to include a new subsystem (such as transition state structures, see SN2 example), you will need to initialize the procedure again. This is very simple\u2014you only need to create a new $WORK_DIR and include the necessary files in user_files/ for each extra system you want to add. To initiate the iterative training procedure, you should create in your $WORK_DIR two folders: user_files/ and data/ . In user_files/ you will store all the files needed for each step. You can find some templates to start with in the GitHub Repository , now available in your machine at your ArcaNN installation location arcann_training/examples/user_files/ . For the exploration step, you must adapt the template files found in exploration_lammps/ or exploration_sander_emle/ depending of your choice. You will need the following files: The input files: SYSTEM.in for LAMMPS and SYSTEM.xml for i-PI. The plumed files: plumed_SYSTEM.dat where SYSNAME refers to the system name (additional PLUMED files can be used as plumed_*_SYSNAME.dat , which will also be taken into account for explorations). For the labeling step, use the template files found in labeling_cp2k/ or labeling_orca/ . You will need the following files: The input files : [1-2]_SYSNAME_labeling_XXXXX_[cluster].inp , where [cluster] refers to the short string selected for the labeling cluster in the machine.json ; see Labeling . For the training step, from training_deepmd you will need: A DeePMD-kit JSON file named dptrain_VERSION.json , where VERSION is the DeePMD-kit version that you will use ( e.g. , 2.1 ; currently supported versions are 2.0 , 2.1 , 2.2 , and 3.0 ). The SLURM scripts for individual jobs and for job arrays are organised by step in several fordels. Prepare your files according to your software choice for each step. You can fin them in: job_exploration_lammps_slurm and job_exploration_sander_emle_slurm for exploration. job_labeling_orca_slurm and job_labeling_cp2k_slurm for the labeling. job_training_deepmd_slurm for training. job_test_deepmd_slurm for testing. We strongly advise you to create the previous files starting from the templates, as they contain replaceable strings for the key parameters that will be updated by the procedure. A representative file in the LAMMPS Data Format format for each system , named SYSTEM.lmp , where SYSTEM refers to the system name (we will refer to them as LMP files). This file represent the configuration of the system , with the number of atoms and the number of types of atoms, the simulation cell dimension, the atomic masses for each type and the atomic geometry of your system . They will be used as starting point for the first exploration. The order of the atoms in the LMP files must be identical for every system and must match the order indicated in the \"type_map\" keyword of the DeePMD-kit dptrain_VERSION.json training file. A properties file must be provided and named properties.txt . This is file will be used by atomsk . In the case you have several systems with different chemical composition, the properties file must be the same for all systems to ensure consistant type mapping. Then, gather all these files and store them inside the user_files/ directory. Don't create subdirectories inside user_files . Finally, you also need to prepare at least one initial dataset which will be used for your first neural networks training, that you will store in the data/ directory. It must follow DeePMD-kit standards and should contain a type.raw file and set.000/ folder with box.npy , coord.npy , energy.npy and force.npy (see DeePMD-kit documentation ). You can prepare as many initial datasets as you wish and they should all be stored in the $WORK_DIR/data/ folder with a folder name starting with init_ .","title":"Iterative procedure prerequisites"},{"location":"usage/labeling/","text":"Labeling In the labeling phase we will use the CP2K code to compute the electronic energies, atomic forces and (sometimes) the stress tensor of the candidate configurations obtained in the exploration phase. In the case you are performing the labeling step in a different HPC machine, don't forget to copy the data (you must also install the ArcaNN software and create a python environment!) beforehand: rsync -rvu $WORK_DIR USER@OTHER_HPC_MACHINE:PATH_TO_WORKDIR For this we need to go to the XXX-labeling folder and as usual run the prepare phase. It is very important to have a look at the default_input.json of the prepare phase to choose the computational resources to be used in the electronic structure calculations (number of nodes and MPI/OpenMP tasks). Note that the default values are insufficient for most condensed systems (due to the large number of atoms), so you should have previously determined the resources required by your specific system(s). { \"step_name\": \"labeling\", \"user_machine_keyword_label\": \"mykeyword1\", \"job_email\": \"\", \"walltime_first_job_h\": [0.5, 0.5, 0.5], \"walltime_second_job_h\": [1.0, 1.0, 1.5], \"nb_nodes\": [1, 1, 1], \"nb_mpi_per_node\": [32, 32, 64], \"nb_threads_per_mpi\": [2, 2, 2], } The \"use_machine_keyword_label\" keyword corresponds to the partition in the HPC machine, The \"nb_mpi_per_node\" and \"nb_nodes\" keywords set the number of CPU nodes used for the labeling. The wall times should be set for the first iteration but can be guessed automatically later using the average time per CP2K calculation measured in the previous iteration. Once you have executed this phase, folders will have been created for each subsystem within which there will be as many folders as candidate configurations (maximum number of 99999 per iteration), containing all required files to run CP2K. Make sure that you have prepared (and correctly named!) Slurm submission files for your machine in the $WORK_DIR/user_files/ folder (see Initialization ), from the template files. For CP2K calculations, 2 scripts must be prepared : a first quick calculation at a lower level of theory and then a second one at our reference level. You can then submit the calculations by executing the launch phase. Once these are finished you can check the results with the check phase. Since candidate configurations are not always very stable (or even physically meaningful if you were too generous with deviation thresholds) some DFT calculations might not have converged. This will be indicated in the output of the check phase. You can either perform manually the calculations with a different setup until the result is satisfactory or skip the problematic configurations by creating empty skip files in the folders that should be ignored. Keep running check until you get a \"Success!\" message. Use the extract phase to set up everything for the training phase and eventually run the clean phase to clean up your folder. CP2K wavefunctions might be stored in an archive with a command given by the code that must be executed manually (if one wishes to keep these files as, for example, starting points for higher level calculations). You can also delete all files but the archives created by the code if you want. We have now augmented our total training set and might do a new training iteration and keep iterating until convergence is reached!","title":"Labeling"},{"location":"usage/labeling/#labeling","text":"In the labeling phase we will use the CP2K code to compute the electronic energies, atomic forces and (sometimes) the stress tensor of the candidate configurations obtained in the exploration phase. In the case you are performing the labeling step in a different HPC machine, don't forget to copy the data (you must also install the ArcaNN software and create a python environment!) beforehand: rsync -rvu $WORK_DIR USER@OTHER_HPC_MACHINE:PATH_TO_WORKDIR For this we need to go to the XXX-labeling folder and as usual run the prepare phase. It is very important to have a look at the default_input.json of the prepare phase to choose the computational resources to be used in the electronic structure calculations (number of nodes and MPI/OpenMP tasks). Note that the default values are insufficient for most condensed systems (due to the large number of atoms), so you should have previously determined the resources required by your specific system(s). { \"step_name\": \"labeling\", \"user_machine_keyword_label\": \"mykeyword1\", \"job_email\": \"\", \"walltime_first_job_h\": [0.5, 0.5, 0.5], \"walltime_second_job_h\": [1.0, 1.0, 1.5], \"nb_nodes\": [1, 1, 1], \"nb_mpi_per_node\": [32, 32, 64], \"nb_threads_per_mpi\": [2, 2, 2], } The \"use_machine_keyword_label\" keyword corresponds to the partition in the HPC machine, The \"nb_mpi_per_node\" and \"nb_nodes\" keywords set the number of CPU nodes used for the labeling. The wall times should be set for the first iteration but can be guessed automatically later using the average time per CP2K calculation measured in the previous iteration. Once you have executed this phase, folders will have been created for each subsystem within which there will be as many folders as candidate configurations (maximum number of 99999 per iteration), containing all required files to run CP2K. Make sure that you have prepared (and correctly named!) Slurm submission files for your machine in the $WORK_DIR/user_files/ folder (see Initialization ), from the template files. For CP2K calculations, 2 scripts must be prepared : a first quick calculation at a lower level of theory and then a second one at our reference level. You can then submit the calculations by executing the launch phase. Once these are finished you can check the results with the check phase. Since candidate configurations are not always very stable (or even physically meaningful if you were too generous with deviation thresholds) some DFT calculations might not have converged. This will be indicated in the output of the check phase. You can either perform manually the calculations with a different setup until the result is satisfactory or skip the problematic configurations by creating empty skip files in the folders that should be ignored. Keep running check until you get a \"Success!\" message. Use the extract phase to set up everything for the training phase and eventually run the clean phase to clean up your folder. CP2K wavefunctions might be stored in an archive with a command given by the code that must be executed manually (if one wishes to keep these files as, for example, starting points for higher level calculations). You can also delete all files but the archives created by the code if you want. We have now augmented our total training set and might do a new training iteration and keep iterating until convergence is reached!","title":"Labeling"},{"location":"usage/start/","text":"Using ArcaNN Iterations, Steps and Phases of the Iterative Procedure At this stage, ArcaNN is installed in your machine, and you have made the necessary changes to adapt it (see HPC Configuration ). As in the GitHub Repository , you can now find in the location where you installed ArcaNN, an arcann_traininig/ folder containing several files, as well as the arcann_training/ scripts, a tools/ directory and a examples/ directory. To start the procedure, create an empty directory anywhere you like that will be your iterative training working directory. We will refer to this directory by the variable name $WORK_DIR . We will describe the prerequisites , and then the initialization , training , exploration , labeling steps and, the optional test . At the end of each step description, we include an example. As described in more detail below, training the NNP proceeds in iterations consisting of three steps : exploration, labeling, and training. Each step is broken down into elementary tasks, which we call phases . Each iteration will have three folders: XXX-exploration, XXX-labeling, and XXX-training ( e.g. , XXX is 003 for the 3rd iteration). Each step is executed in its corresponding folder by running, in order, the relevant phases with the following command: python -m arcann_training STEP_NAME PHASE_NAME where STEP_NAME refers to the current step ( initialization , exploration , labeling , training , or test ) and PHASE_NAME is the specific task that needs to be performed within that step . This will become clearer with examples in the sections below, where each step is explained. The following tables provide a brief description of the phases in each step , in the correct order. Since initialization has only a single start phase , which is self-explanatory, it is detailed in the example below. Exploration Phase Description prepare Prepares the folders for running the exploration MDs of all systems (automatically generating input files required for each simulation). launch Submits the MD simulation to the specified partition of the cluster, usually with a SLURM array. check Verifies whether the exploration simulations have completed successfully. If any simulations ended abruptly, it indicates which ones, allowing the user to skip or force them (see Exploration ). deviate Reads the model deviation (maximum deviation between atomic forces predicted by the committee of NN) along the trajectories of each system and identifies configurations that are candidates (deviations within specified boundaries; see Exploration ). extract Extracts a user-defined number of candidate configurations per system , saving them to a SYSNAME/candidates_SYSNAME.xyz file for labeling and addition to the NNP training set. clean Removes files that are no longer required (optional). Labeling Phase Description prepare Prepares folders and files to run electronic structure calculations on identified candidates of each system , obtaining the energies and forces required to train the NNP. launch Submits the calculations with one SLURM array per system . check Verifies that calculations have completed successfully. If any calculations finished abruptly, it writes their index to a text file in the corresponding SYSNAME/ folder. The user must decide whether to skip or resubmit manually each failed calculation before proceeding. extract Extracts necessary information from the CP2K outputs and builds DeePMD-kit \"systems\"/datasets for each system (stored in the $WORK_DIR/data/ folder). clean Removes files that are no longer required and compresses the calculation outputs into an archive (optional). Training Phase Description prepare Prepares folders and files for training and the user-defined number of independent NNPs to be used in the next iteration. launch Submits the training calculations using the dp train code from DeePMD-kit. check Verifies whether the training has completed successfully. If any traoining ended abruptly, they need to be resubmitted manually to ensure the training finishes correctly. freeze Freezes the NN parameters into a binary file ( .pb extension for TensorFlow back-end) usable with LAMMPS and Python. This is done with the dp freeze code from DeePMD-kit. check_freeze Verifies that the calculations completed successfully. If any calculations finished abruptly, they must be resubmitted manually to ensure freezing completes correctly. compress Compresses the NNP by modifying the .pb file to enhance performance with minimal loss of accuracy. Uses the dp compress code from DeePMD-kit (optional). check_compress Verifies that the calculations completed successfully. If any calculations finished abruptly, they must be resubmitted manually to ensure compressing completes correctly. increment Changes the iteration number in control and creates new exploration , labeling , and training folders for the next iteration. clean Removes files that are no longer required (optional). Test Phase Description prepare Prepares folders and files for testing the performance of the current iteration's NNP on each dataset included in the training set. launch Submits the testing calculations using the dp test code from DeePMD-kit. If you need \"detail files\" generated by dp test , include this directly in the job_test_deepmd file. check Verifies whether the calculations have completed successfully. clean Removes files that are no longer required (optional). If \"detail files\" weren't requested, the XXX-test/ folder will be removed, as all the step information is consolidated in the control/test_XXX.json file. Otherwise, the \"detail files\" will be compressed into .npy format and stored in XXX-test/ . Parameters Parameters will need to be defined for most phases of each step ( e.g. , length of MD simulations, temperature, number of CPU tasks for labeling calculations, etc.). This is done via input files in the JSON format. Executing phase without an input file will use all the default values (see the exploration.json file in examples/inputs for all exploration phases) and write them to a default_json.json file. This file serves as a reminder of what the default values are. After successfully executing a phase , a used_input.json file will be created, indicating which parameters ArcaNN used for that phase . It will be appended with additional parameters after a subsequent phase ( e.g. , after exploration prepare , a used_input.json is created and appended after exploration deviate with parameters specific to the deviate phase). If you want to override the default values for a phase, simply create an input.json file with the parameters you want to change. For example, to override the number of picoseconds for the exploration prepare phase, add an input.json file like this: { \"exp_time_ps\": 100 } And run or rerun exploration prepare : you will see within the used_input.json that the requested parameters have been read, and that dependent parameters ( e.g. , walltime) have been adjusted accordingly. The parameters indicated in an input.json file will always override the default or auto-calculated ones, and for some of them, the values will persist . For instance, if you provided an override for max_candidates in iteration 003 , it will be maintained in iteration 004 without requiring another input.json . We will now describe each step of the concurrent learning procedure in detail.","title":"Using ArcaNN"},{"location":"usage/start/#using-arcann","text":"","title":"Using ArcaNN"},{"location":"usage/start/#iterations-steps-and-phases-of-the-iterative-procedure","text":"At this stage, ArcaNN is installed in your machine, and you have made the necessary changes to adapt it (see HPC Configuration ). As in the GitHub Repository , you can now find in the location where you installed ArcaNN, an arcann_traininig/ folder containing several files, as well as the arcann_training/ scripts, a tools/ directory and a examples/ directory. To start the procedure, create an empty directory anywhere you like that will be your iterative training working directory. We will refer to this directory by the variable name $WORK_DIR . We will describe the prerequisites , and then the initialization , training , exploration , labeling steps and, the optional test . At the end of each step description, we include an example. As described in more detail below, training the NNP proceeds in iterations consisting of three steps : exploration, labeling, and training. Each step is broken down into elementary tasks, which we call phases . Each iteration will have three folders: XXX-exploration, XXX-labeling, and XXX-training ( e.g. , XXX is 003 for the 3rd iteration). Each step is executed in its corresponding folder by running, in order, the relevant phases with the following command: python -m arcann_training STEP_NAME PHASE_NAME where STEP_NAME refers to the current step ( initialization , exploration , labeling , training , or test ) and PHASE_NAME is the specific task that needs to be performed within that step . This will become clearer with examples in the sections below, where each step is explained. The following tables provide a brief description of the phases in each step , in the correct order. Since initialization has only a single start phase , which is self-explanatory, it is detailed in the example below.","title":"Iterations, Steps and Phases of the Iterative Procedure"},{"location":"usage/start/#exploration","text":"Phase Description prepare Prepares the folders for running the exploration MDs of all systems (automatically generating input files required for each simulation). launch Submits the MD simulation to the specified partition of the cluster, usually with a SLURM array. check Verifies whether the exploration simulations have completed successfully. If any simulations ended abruptly, it indicates which ones, allowing the user to skip or force them (see Exploration ). deviate Reads the model deviation (maximum deviation between atomic forces predicted by the committee of NN) along the trajectories of each system and identifies configurations that are candidates (deviations within specified boundaries; see Exploration ). extract Extracts a user-defined number of candidate configurations per system , saving them to a SYSNAME/candidates_SYSNAME.xyz file for labeling and addition to the NNP training set. clean Removes files that are no longer required (optional).","title":"Exploration"},{"location":"usage/start/#labeling","text":"Phase Description prepare Prepares folders and files to run electronic structure calculations on identified candidates of each system , obtaining the energies and forces required to train the NNP. launch Submits the calculations with one SLURM array per system . check Verifies that calculations have completed successfully. If any calculations finished abruptly, it writes their index to a text file in the corresponding SYSNAME/ folder. The user must decide whether to skip or resubmit manually each failed calculation before proceeding. extract Extracts necessary information from the CP2K outputs and builds DeePMD-kit \"systems\"/datasets for each system (stored in the $WORK_DIR/data/ folder). clean Removes files that are no longer required and compresses the calculation outputs into an archive (optional).","title":"Labeling"},{"location":"usage/start/#training","text":"Phase Description prepare Prepares folders and files for training and the user-defined number of independent NNPs to be used in the next iteration. launch Submits the training calculations using the dp train code from DeePMD-kit. check Verifies whether the training has completed successfully. If any traoining ended abruptly, they need to be resubmitted manually to ensure the training finishes correctly. freeze Freezes the NN parameters into a binary file ( .pb extension for TensorFlow back-end) usable with LAMMPS and Python. This is done with the dp freeze code from DeePMD-kit. check_freeze Verifies that the calculations completed successfully. If any calculations finished abruptly, they must be resubmitted manually to ensure freezing completes correctly. compress Compresses the NNP by modifying the .pb file to enhance performance with minimal loss of accuracy. Uses the dp compress code from DeePMD-kit (optional). check_compress Verifies that the calculations completed successfully. If any calculations finished abruptly, they must be resubmitted manually to ensure compressing completes correctly. increment Changes the iteration number in control and creates new exploration , labeling , and training folders for the next iteration. clean Removes files that are no longer required (optional).","title":"Training"},{"location":"usage/start/#test","text":"Phase Description prepare Prepares folders and files for testing the performance of the current iteration's NNP on each dataset included in the training set. launch Submits the testing calculations using the dp test code from DeePMD-kit. If you need \"detail files\" generated by dp test , include this directly in the job_test_deepmd file. check Verifies whether the calculations have completed successfully. clean Removes files that are no longer required (optional). If \"detail files\" weren't requested, the XXX-test/ folder will be removed, as all the step information is consolidated in the control/test_XXX.json file. Otherwise, the \"detail files\" will be compressed into .npy format and stored in XXX-test/ .","title":"Test"},{"location":"usage/start/#parameters","text":"Parameters will need to be defined for most phases of each step ( e.g. , length of MD simulations, temperature, number of CPU tasks for labeling calculations, etc.). This is done via input files in the JSON format. Executing phase without an input file will use all the default values (see the exploration.json file in examples/inputs for all exploration phases) and write them to a default_json.json file. This file serves as a reminder of what the default values are. After successfully executing a phase , a used_input.json file will be created, indicating which parameters ArcaNN used for that phase . It will be appended with additional parameters after a subsequent phase ( e.g. , after exploration prepare , a used_input.json is created and appended after exploration deviate with parameters specific to the deviate phase). If you want to override the default values for a phase, simply create an input.json file with the parameters you want to change. For example, to override the number of picoseconds for the exploration prepare phase, add an input.json file like this: { \"exp_time_ps\": 100 } And run or rerun exploration prepare : you will see within the used_input.json that the requested parameters have been read, and that dependent parameters ( e.g. , walltime) have been adjusted accordingly. The parameters indicated in an input.json file will always override the default or auto-calculated ones, and for some of them, the values will persist . For instance, if you provided an override for max_candidates in iteration 003 , it will be maintained in iteration 004 without requiring another input.json . We will now describe each step of the concurrent learning procedure in detail.","title":"Parameters"},{"location":"usage/test/","text":"Test Test It is possible to perform tests at every iteration of the learning procedure (the code will create XXX-test/ folders at every increment phase of a training step). However, doing this at every iteration is rather time consuming and is not really necessary (although you should obviously test your converged NNP thoroughly). Therefore, documentation on how to test at every iteration within the arcann_training procedure is still not ready, sorry!","title":"Test"},{"location":"usage/test/#test","text":"","title":"Test"},{"location":"usage/test/#test_1","text":"It is possible to perform tests at every iteration of the learning procedure (the code will create XXX-test/ folders at every increment phase of a training step). However, doing this at every iteration is rather time consuming and is not really necessary (although you should obviously test your converged NNP thoroughly). Therefore, documentation on how to test at every iteration within the arcann_training procedure is still not ready, sorry!","title":"Test"},{"location":"usage/training/","text":"Training During the training procedure you will use DeePMD-kit to train neural networks on the data sets that you have thus far generated (or on the initial ones only for the 000-training ). In order to do this go to the current iteration training folder XXX-training . There are 9 phases (see Iterations, Steps and Phases of the Iterative Procedure ) that you must now execute in order after having optionally modified the input.json file to define the relevant parameters (in case you want something different from the defaults, which are written to default_input.json in the prepare phase). The input keywords that you should check the most carefully are those related to the first phase prepare , as this sets all the important parameters for the training. Some phases will simply submit Slurm jobs (model training, freezing and compressing). You must wait for the jobs to finish before executing the next phase (generally this will be a check phase that will tell you that jobs have failed or are currently running). Once you have executed the first 8 phases, the training iteration is done! Executing the 9-th phases is optional, as this will only remove intermediary files. After running the initialization step described in the previous example, you must now perform the first training phase. Update (or copy for the first time) the full $WORK_DIR from your local machine to your HPC machine (where you must have also a copy of this repository and an environment in which it is installed): rsync -rvu $WORK_DIR USER@HPC-MACHINE:/PATH/TO/WORK_DIR Now go to the empty 000-training folder created by the script execute the prepare phase: python -m arcann_training training prepare This will create three folders 1/ , 2/ and 3/ and a copy of your data/ folder, as well as a default_input.json file containing the default training parameters. If you want to modify some of the default values you can create a input.json file from the default_input.json file that looks like this: { \"step_name\": \"training\", \"user_machine_keyword_train\": \"mykeyword1\", \"user_machine_keyword_freeze\": \"mykeyword2\", \"user_machine_keyword_compress\": \"mykeyword2\", \"slurm_email\": \"\", \"use_initial_datasets\": true, \"use_extra_datasets\": false, \"deepmd_model_version\": 2.2, \"job_walltime_train_h\": 4, \"mean_s_per_step\": -1, \"start_lr\": 0.001, \"stop_lr\": 1e-06, \"decay_rate\": 0.9172759353897796, \"decay_steps\": 5000, \"decay_steps_fixed\": false, \"numb_steps\": 400000, \"numb_test\": 0, } Here the \"user_machine_keyword\" should match the \"myHPCkeyword1\" keyword in the machine.json (see HPC Configuration ). Note that the more performant GPUs should ideally be used for training, while the other steps could be alllocated to less performant GPUs or even to CPUs. Here we used a user chosen walltime of 4 h (instead of the default indicated by -1 , which will calculate the job walltime automatically based on your previous trainings). The followiing keywords are the DeePMD training parameters, that you can eventually modify or keep the default values. We can then execute all the other phases in order (waiting for Slurm jobs to finish!). That's it! Now you just need to update the local folder: rsync -rvu USER@HPC-MACHINE.fr:/PATH/TO/WORK_DIR $WORK_DIR and you are ready to move on to the exploration phase! Notes: At some point during the iterative procedure we might want to get rid of our initial data sets, we would only need to set the use_initial_datasets variable to False . We might also have generated some data independently from the iterative procedure that we might want to start using, this can be done by copying the corresponding DeePMD-kit systems to data/ , prefixing their names by extra_ and setting the use_extra_datasets variable to True . At the end of the step the last phase increment will create the folders needed for the next iteration, save the current NNPs (stored as graph files graph_[nnp_count]_XXX[_compressed].pb ) into the $WORK_DIR/NNP folder and write a control/training_XXX.json file with all parameters used during training.","title":"Training"},{"location":"usage/training/#training","text":"During the training procedure you will use DeePMD-kit to train neural networks on the data sets that you have thus far generated (or on the initial ones only for the 000-training ). In order to do this go to the current iteration training folder XXX-training . There are 9 phases (see Iterations, Steps and Phases of the Iterative Procedure ) that you must now execute in order after having optionally modified the input.json file to define the relevant parameters (in case you want something different from the defaults, which are written to default_input.json in the prepare phase). The input keywords that you should check the most carefully are those related to the first phase prepare , as this sets all the important parameters for the training. Some phases will simply submit Slurm jobs (model training, freezing and compressing). You must wait for the jobs to finish before executing the next phase (generally this will be a check phase that will tell you that jobs have failed or are currently running). Once you have executed the first 8 phases, the training iteration is done! Executing the 9-th phases is optional, as this will only remove intermediary files. After running the initialization step described in the previous example, you must now perform the first training phase. Update (or copy for the first time) the full $WORK_DIR from your local machine to your HPC machine (where you must have also a copy of this repository and an environment in which it is installed): rsync -rvu $WORK_DIR USER@HPC-MACHINE:/PATH/TO/WORK_DIR Now go to the empty 000-training folder created by the script execute the prepare phase: python -m arcann_training training prepare This will create three folders 1/ , 2/ and 3/ and a copy of your data/ folder, as well as a default_input.json file containing the default training parameters. If you want to modify some of the default values you can create a input.json file from the default_input.json file that looks like this: { \"step_name\": \"training\", \"user_machine_keyword_train\": \"mykeyword1\", \"user_machine_keyword_freeze\": \"mykeyword2\", \"user_machine_keyword_compress\": \"mykeyword2\", \"slurm_email\": \"\", \"use_initial_datasets\": true, \"use_extra_datasets\": false, \"deepmd_model_version\": 2.2, \"job_walltime_train_h\": 4, \"mean_s_per_step\": -1, \"start_lr\": 0.001, \"stop_lr\": 1e-06, \"decay_rate\": 0.9172759353897796, \"decay_steps\": 5000, \"decay_steps_fixed\": false, \"numb_steps\": 400000, \"numb_test\": 0, } Here the \"user_machine_keyword\" should match the \"myHPCkeyword1\" keyword in the machine.json (see HPC Configuration ). Note that the more performant GPUs should ideally be used for training, while the other steps could be alllocated to less performant GPUs or even to CPUs. Here we used a user chosen walltime of 4 h (instead of the default indicated by -1 , which will calculate the job walltime automatically based on your previous trainings). The followiing keywords are the DeePMD training parameters, that you can eventually modify or keep the default values. We can then execute all the other phases in order (waiting for Slurm jobs to finish!). That's it! Now you just need to update the local folder: rsync -rvu USER@HPC-MACHINE.fr:/PATH/TO/WORK_DIR $WORK_DIR and you are ready to move on to the exploration phase! Notes: At some point during the iterative procedure we might want to get rid of our initial data sets, we would only need to set the use_initial_datasets variable to False . We might also have generated some data independently from the iterative procedure that we might want to start using, this can be done by copying the corresponding DeePMD-kit systems to data/ , prefixing their names by extra_ and setting the use_extra_datasets variable to True . At the end of the step the last phase increment will create the folders needed for the next iteration, save the current NNPs (stored as graph files graph_[nnp_count]_XXX[_compressed].pb ) into the $WORK_DIR/NNP folder and write a control/training_XXX.json file with all parameters used during training.","title":"Training"}]}